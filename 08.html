

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Basic Analysis of Spike Train Data &#8212; Case Studies in Neural Data Analysis</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/mystnb.js"></script>
    <script src="_static/custom.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script async="async" src="_static/thebelab.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="canonical" href="https://mark-kramer.github.io/Case-Studies-Python/08.html" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Point Process Generalized Linear Models" href="09.html" />
    <link rel="prev" title="Cross-Frequency Coupling" href="07.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">


<!-- Opengraph tags -->
<meta property="og:url"         content="https://mark-kramer.github.io/Case-Studies-Python/08.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Basic Analysis of Spike Train Data" />
<meta property="og:description" content="Basic Analysis of Spike Train Data  <div class="question">   Synopsis  Data: Spontaneous spiking activity from a retinal neuron in culture, exposed to low-light" />
<meta property="og:image"       content="https://mark-kramer.github.io/Case-Studies-Python/_static/logo.png" />

<meta name="twitter:card" content="summary">


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Case Studies in Neural Data Analysis</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="01.html">1. Python for the practicing neuroscientist</a>
  </li>
  <li class="">
    <a href="02.html">2. The Event-Related Potential</a>
  </li>
  <li class="">
    <a href="03.html">3. The Power Spectrum (Part 1)</a>
  </li>
  <li class="">
    <a href="04.html">4. The Power Spectrum (Part 2)</a>
  </li>
  <li class="">
    <a href="05.html">5. Analysis of Coupled Rhythms</a>
  </li>
  <li class="">
    <a href="06.html">6. Filtering Field Data</a>
  </li>
  <li class="">
    <a href="07.html">7. Cross-Frequency Coupling</a>
  </li>
  <li class="active">
    <a href="">8. Basic Analysis of Spike Train Data</a>
  </li>
  <li class="">
    <a href="09.html">9. Point Process Generalized Linear Models</a>
  </li>
  <li class="">
    <a href="10.html">10. Analysis of Rhythmic Spike Train Data</a>
  </li>
  <li class="">
    <a href="11.html">11. Spike-Field Coherence</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Extra notebooks</p>
</li>
  <li class="">
    <a href="IF.html">12. The integrate and fire neuron</a>
  </li>
  <li class="">
    <a href="HH.html">13. The Hodgkin-Huxley model</a>
  </li>
  <li class="">
    <a href="Perceptron.html">14. Training a Perceptron</a>
  </li>
  <li class="">
    <a href="Backprop.html">15. Backpropagation</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="_sources/08.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Source interaction buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
            <div class="dropdown-buttons sourcebuttons">
                <a class="repository-button" href="https://github.com/Mark-Kramer/Case-Studies-Python/"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left" title="Source repository"><i class="fab fa-github"></i>repository</button></a>
                <a class="issues-button" href="https://github.com/Mark-Kramer/Case-Studies-Python//issues/new?title=Issue%20on%20page%20%2F08.html&body=Your%20issue%20content%20here."><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left" title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
                
            </div>
        </div>
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
            <div class="dropdown-buttons">
                
                <a class="binder-button" href="https://mybinder.org/v2/gh/Mark-Kramer/Case-Studies-Python/binder?urlpath=tree/08.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip" data-placement="left"><img class="binder-button-logo" src="_static/images/logo_binder.svg" alt="Interact on binder">Binder</button></a>
                
                
                <button type="button" class="btn btn-secondary topbarbtn thebelab-launch-button" onclick="initThebelab()" title="Launch Thebelab" data-toggle="tooltip" data-placement="left"><i class="fas fa-rocket"></i><span style="margin-left: .4em;">ThebeLab</span></button>
                
            </div>
        </div>
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#on-ramp-visualizing-spike-train-data-in-python" class="nav-link">On-ramp: visualizing spike train data in Python</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#introduction" class="nav-link">Introduction</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#case-study-data" class="nav-link">Case Study Data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#goal" class="nav-link">Goal</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#tools" class="nav-link">Tools</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-analysis" class="nav-link">Data Analysis</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#examining-the-interspike-intervals" class="nav-link">Examining the Interspike Intervals</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#examining-binned-spike-increments" class="nav-link">Examining Binned Spike Increments</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#does-the-observed-fano-factor-differ-from-1" class="nav-link">Does the observed Fano factor differ from 1?</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#computing-autocorrelations-for-the-increments" class="nav-link">Computing Autocorrelations for the Increments</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#computing-autocorrelations-of-the-isis" class="nav-link">Computing Autocorrelations of the ISIs</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#building-statistical-models-of-the-isis" class="nav-link">Building Statistical Models of the ISIs</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#a-more-advanced-statistical-model" class="nav-link">A More Advanced Statistical Model.</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#summary" class="nav-link">Summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#appendix-spike-count-mean-and-variance-for-a-poisson-process" class="nav-link">Appendix: Spike Count Mean and Variance for a Poisson Process</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a id="top"></a></p>
<div class="section" id="basic-analysis-of-spike-train-data">
<h1>Basic Analysis of Spike Train Data<a class="headerlink" href="#basic-analysis-of-spike-train-data" title="Permalink to this headline">¶</a></h1>
<div class="question">
<p><em><strong>Synopsis</strong></em></p>
<p><strong>Data:</strong> Spontaneous spiking activity from a retinal neuron in culture, exposed to low-light and high-light environments.</p>
<p><strong>Goal:</strong> Visualize spike trains, compute and interpret descriptive statistics, and build simple models of interspike interval distributions as a function of the ambient light level.</p>
<p><strong>Tools:</strong> Raster plots, interspike interval histograms, firing rate, autocorrelograms, maximum likelihood estimation, Kolmogorov-Smirnov plots.</p>
</div><ul class="simple">
<li><p><a class="reference external" href="#onramp">On-ramp: visualizing spike train data in Python</a></p></li>
<li><p><a class="reference external" href="#introduction">Introduction</a></p></li>
<li><p><a class="reference external" href="#data-analysis">Data analysis</a></p>
<ol class="simple">
<li><p><a class="reference external" href="#visual-inspection">Visual inspection</a></p></li>
<li><p><a class="reference external" href="#isi">Examining the Interspike Intervals</a></p></li>
<li><p><a class="reference external" href="#bsi">Examining Binned Spike Increments</a></p></li>
<li><p><a class="reference external" href="#autocorrelations">Computing Autocorrelations for the Increments</a></p></li>
<li><p><a class="reference external" href="#acISI">Computing Autocorrelations of the ISIs</a></p></li>
<li><p><a class="reference external" href="#models">Building Statistical Models of the ISIs</a></p></li>
</ol>
</li>
<li><p><a class="reference external" href="#summary">Summary</a></p></li>
<li><p><a class="reference external" href="#appendix">Appendix: Spike Count Mean and Variance for a Poisson Process</a></p></li>
</ul>
<p><a id="onramp"></a></p>
<div class="section" id="on-ramp-visualizing-spike-train-data-in-python">
<h2>On-ramp: visualizing spike train data in Python<a class="headerlink" href="#on-ramp-visualizing-spike-train-data-in-python" title="Permalink to this headline">¶</a></h2>
<p>We begin this notebook with an “<em>on-ramp</em>” to analysis. The purpose of this on-ramp is to introduce you immediately to a core concept in this notebook: techniques to visualize spike train data in Python. You may not understand all aspects of the program here, but that’s not the point. Instead, the purpose of this on-ramp is to  illustrate what <em>can</em> be done. Our advice is to simply run the code below and see what happens …</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">scipy.io</span> <span class="k">as</span> <span class="nn">sio</span>              
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Change the default figure size</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">sio</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="s1">&#39;matfiles/08_spikes-1.mat&#39;</span><span class="p">)</span>       <span class="c1"># Load the spike train data</span>
<span class="n">SpikesLow</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;SpikesLow&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>         <span class="c1"># ... and get the spike times for low-light condition.</span>

<span class="n">ISIsLow</span> <span class="o">=</span> <span class="n">diff</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">)</span>             <span class="c1"># Compute ISIs in the low-light condition</span>
                                         <span class="c1"># Fit a statistical model to the ISIs.</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>           <span class="c1"># Define 1 ms bins.</span>
<span class="n">Nlow</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>                      <span class="c1"># Length of low-light condition.</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">ISIsLow</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>                      <span class="c1"># Mean of inverse Gaussian</span>
<span class="n">lbda</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">ISIsLow</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>    <span class="c1"># ... and shape parameter</span>
<span class="n">model</span> <span class="o">=</span> <span class="p">(</span>                                   <span class="c1"># ... to create the model.</span>
    <span class="n">sqrt</span><span class="p">(</span><span class="n">lbda</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">pi</span> <span class="o">/</span> <span class="n">bins</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> 
    <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lbda</span> <span class="o">*</span> <span class="p">(</span><span class="n">bins</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">mu</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">bins</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span>
<span class="p">)</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>                             <span class="c1"># Numerator to 0 faster than denominator.</span>

<span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>                         <span class="c1"># Plot the data and the model,</span>
<span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>  <span class="c1"># Compute histogram,</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>             <span class="c1"># ... convert to probability,</span>
<span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">prob</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>     <span class="c1"># ... and plot probability.</span>
<span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>                   <span class="c1"># Plot the model.</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>                       <span class="c1"># xlim from 0 to 200 ms.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;ISI [s]&#39;</span><span class="p">)</span>                        <span class="c1"># Label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>

<span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>                         <span class="c1"># Plot the KS plot</span>
<span class="n">FmodLow</span> <span class="o">=</span> <span class="n">cumsum</span><span class="p">(</span><span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>          <span class="c1"># Define the model CDF,</span>
<span class="n">FempLow</span> <span class="o">=</span> <span class="n">cumsum</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>                <span class="c1"># ... and define empirical CDF,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">FmodLow</span><span class="p">,</span> <span class="n">FempLow</span><span class="p">)</span>                   <span class="c1"># ... plot model vs empirical CDF,</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.36</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">Nlow</span><span class="p">),</span><span class="s1">&#39;k:&#39;</span><span class="p">)</span>  <span class="c1"># ... upper confidence bound,</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.36</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">Nlow</span><span class="p">),</span><span class="s1">&#39;k:&#39;</span><span class="p">)</span>  <span class="c1"># ... lower confidence bound,</span>
<span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>                   <span class="c1"># ... set the axes ranges,</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Model CDF&#39;</span><span class="p">)</span>                      <span class="c1"># ... and label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Empirical CDF&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="stderr docutils container">
<pre class="stderr literal-block">/anaconda3/envs/csn/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide
/anaconda3/envs/csn/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in multiply
</pre>
</div>
<img alt="_images/08_4_1.png" src="_images/08_4_1.png" />
</div>
</div>
<div class="question">
<p><strong>Q:</strong> Try to read the code above. Can you see how it loads data, computes the interspike intervals (ISIs) and fits a statistical model, and assess the model fit?</p>
<p><strong>A:</strong> If you’ve not analyzed spike train data before, that’s an especially difficult question. Please continue on to learn this <strong>and more</strong>!</p>
</div><p><a id="introduction"></a></p>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Neurons in the retina typically respond to patterns of light displayed over small sections of the visual field. However, when retinal neurons are grown in culture and held under constant light and environmental conditions, they will still spontaneously fire action potentials. In a fully functioning retina, this spontaneous activity is sometimes described as background firing activity, which is modulated as a function of visual stimuli. It is useful to understand the properties of this background activity in order to determine in future experiments how these firing properties are affected by specific stimuli.</p>
<div class="section" id="case-study-data">
<h3>Case Study Data<a class="headerlink" href="#case-study-data" title="Permalink to this headline">¶</a></h3>
<p>A researcher examining the background firing properties of one of these neurons contacts you to discuss his data. He records the spiking activity in one of two states, with the room lights off (low ambient light levels) or with the room lights on (high ambient light levels). He would like to collaborate with you to determine whether there is a difference in background firing between these two conditions, and whether one environment is more conducive to future experimental analyses. He records the spiking activity for 30 seconds in each condition.</p>
</div>
<div class="section" id="goal">
<h3>Goal<a class="headerlink" href="#goal" title="Permalink to this headline">¶</a></h3>
<p>Typically the first step in any data analysis involves visualizing and using simple descriptive statistics to characterize pertinent features of the data. For time series data that take on a continuous value at each time point, like the field potentials analyzed in earlier notebooks, we typically start by simply plotting each data value as a function of time. For spike train data, things can become a bit more complicated. One reason for this is that there are multiple equivalent ways to describe the same spike train data. The data could be stored as a sequence of spike times; as a sequence of waiting times between spikes, or interspike intervals; or as a discrete time series indicating the number of spikes in discrete time bins. Knowing how to manipulate and visualize spike train data using all these different representations is the first step to understanding the structure present in the data and is the primary goal of this notebook.</p>
</div>
<div class="section" id="tools">
<h3>Tools<a class="headerlink" href="#tools" title="Permalink to this headline">¶</a></h3>
<p>We develop tools in this notebook to visualize spike train data and to provide basic statistical methods appropriate for analyzing spike trains.</p>
<p><a id="data-analysis"></a></p>
</div>
</div>
<div class="section" id="data-analysis">
<h2>Data Analysis<a class="headerlink" href="#data-analysis" title="Permalink to this headline">¶</a></h2>
<p><a id="visual-inspection"></a></p>
<p>Our data analysis begins with visual inspection. To start, let’s load the data into Python for inspection:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare the standard modules </span>
<span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">scipy.io</span> <span class="k">as</span> <span class="nn">sio</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># Change the default figure size</span>

<span class="c1"># ... and notebook specific modules</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gamma</span>      <span class="c1"># Import the gamma object from the SciPy stats toolbox</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">sio</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="s1">&#39;matfiles/08_spikes-1.mat&#39;</span><span class="p">)</span>  <span class="c1"># Load the spike train data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;__header__&#39;, &#39;__version__&#39;, &#39;__globals__&#39;, &#39;SpikesLow&#39;, &#39;SpikesHigh&#39;])
</pre></div>
</div>
</div>
</div>
<div class="question">
<p><strong>Q.</strong> How can we extract the variables of interest from <code class="docutils literal notranslate"><span class="pre">data</span></code>? Hint: Consider the <code class="docutils literal notranslate"><span class="pre">keys()</span></code> method.</p>
</div><p>You should find two non-private variables in the <code class="docutils literal notranslate"><span class="pre">data</span></code> dictionary:</p>
<p><code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code>: spike times over 30 s in the low ambient light condition,</p>
<p><code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code>: spike times over 30 s in the high ambient light condition.</p>
<p>We can take these two variables from <code class="docutils literal notranslate"><span class="pre">data</span></code> so that we can work with them directly.</p>
<div class="python-note">
<p>Recall that the <code class="docutils literal notranslate"><span class="pre">loadmat()</span></code> function outputs a dictionary that contains the variables in the .mat file along with some additional information about the file.</p>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SpikesLow</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;SpikesLow&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">SpikesHigh</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;SpikesHigh&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Each variable is a single vector that gives a set of increasing spike times for the associated condition. The two vectors are of different sizes because the neuron fired a different number of spikes in each condition.</p>
<div class="question">
<p><strong>Q.</strong> What is the size of the vector <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code>?</p>
<p><strong>A.</strong> To answer this in Python, we use the command</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>SpikesLow.shape
</pre></div>
</div>
<p>Python returns the answer</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(750,)
</pre></div>
</div>
<p>which reveals that <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> is a vector with 750 elements (i.e., an array with 750 rows and 1 column). We could also have used <code class="docutils literal notranslate"><span class="pre">len(SpikesLow)</span></code> here since we are working with a vector (1-D) rather than a multidimensional array. Our collaborator who collected the data told us that each row holds a single spike time, and we continue to consider the implications of this statement.</p>
</div><div class="question">
<p><strong>Q.</strong> What is the size of the vector <code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code>?</p>
</div><p>Inspection of the sizes of the vectors <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> and <code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code> reveals an important fact: the neuron fires more in the high-light condition. To make this observation more concrete, let’s compute the firing rate (<span class="math notranslate nohighlight">\(f\)</span>), defined mathematically as</p>
<div class="math notranslate nohighlight">
\[
  f = \frac{n}{T},
  \tag{1}
\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the number of spikes over the time interval <span class="math notranslate nohighlight">\(T\)</span>.</p>
<div class="question">
<p><strong>Q.</strong> What is the firing rate <span class="math notranslate nohighlight">\(f\)</span> of the neuron recorded in the low ambient light condition?</p>
<p><strong>A.</strong> To answer this question, we must first define two quantities of interest: <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(T\)</span>. We consider here the entire duration of the recording, so <span class="math notranslate nohighlight">\(T = 30\)</span> (our collaborator recorded the spiking activity for 30 s in each condition). During this interval, we found that the vector <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> contains 750 spikes. With these two pieces of information, we may compute the firing rate.</p>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="n">T</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;f =&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>f = 25.0
</pre></div>
</div>
</div>
</div>
<p>This tells us that the firing rate is 25 spikes per second, or 25 Hz.</p>
<div class="question">
<p><strong>Q.</strong> Is this single number a good representation of the spike train data? What if the spiking changes dramatically throughout the recording?</p>
</div><div class="question">
<p><strong>Q.</strong> What is the firing rate of the neuron recorded in the high ambient light condition?</p>
</div><p>These calculations allow us to compute a simple number representative of one aspect of the data: the firing rate over the entire duration of the recording. Do the two datasets exhibit a statistically significant change in the firing structure between conditions? Or, does the difference in firing rates lie within the range of expected fluctuations between any two trials of random spiking data? To answer these types of questions, we need to develop statistical methods that are appropriate for analyzing spike trains. Let’s look at the data more carefully and visualize the structure of the spiking in the low ambient light condition. It may be tempting to visualize the spike train by simply plotting the <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> variable,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_25_0.png" src="_images/08_25_0.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> What went wrong here? How do we interpret this plot?</p>
<p><strong>A.</strong> These data are stored as a sequence of time stamps representing an increasing sequence of times at which the neuron spiked. When we run the plot command with only one input vector, we plot an index that runs from 1 to the length of the vector on the <span class="math notranslate nohighlight">\(x\)</span>-axis against the numerical values in that vector on the <span class="math notranslate nohighlight">\(y\)</span>-axis. Therefore the plot shows an increasing line where the <span class="math notranslate nohighlight">\(x\)</span>-axis represents the spike number and the <span class="math notranslate nohighlight">\(y\)</span>-axis represents the spike time. Notice that the vector ends at an <span class="math notranslate nohighlight">\(x\)</span>-axis value of 750, which corresponds to the length of the vector. Also, the values on the <span class="math notranslate nohighlight">\(y\)</span>-axis range from 0 to 30; these correspond to times starting near 0 s and ending near 30 s, as we expect for the 30 s recording. Although this plot is not immediately useful, the results are consistent with our expectations for the data.</p>
</div><p>Instead of the data representation above, we would like to plot the spike train data as a set of points in a single row with <span class="math notranslate nohighlight">\(x\)</span>-coordinates that occur at the spike times. One way to produce such a plot is the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">,</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">),</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>  <span class="c1"># Plot spikes as a row,</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>                                <span class="c1"># ... display times (0, 5) s</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (s)&#39;</span><span class="p">)</span>                          <span class="c1"># ... label the x-axis</span>
<span class="n">yticks</span><span class="p">([])</span>                                  <span class="c1"># ... remove y-axis ticks</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_28_0.png" src="_images/08_28_0.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> What’s happening in the first line of this code?</p>
<p><strong>A.</strong> The plot function receives three inputs. The first input defines the <span class="math notranslate nohighlight">\(x\)</span>-axis values for the plot, which here are the spike times. The second input is itself a function:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ones_like(SpikesLow)
</pre></div>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">ones_like</span></code> produces an array filled entirely with 1s that is the same dimensions as <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code>. The last input to <code class="docutils literal notranslate"><span class="pre">plot</span></code> instructs Python to display the data using the dot symbol. To summarize, we’re calling the <code class="docutils literal notranslate"><span class="pre">plot</span></code> command to display</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\)</span>-axis values: spike times in the low ambient light condition</p></li>
<li><p><span class="math notranslate nohighlight">\(y\)</span>-axis values: 1</p></li>
</ul>
<p>as dots. The next two commands set the range of the <span class="math notranslate nohighlight">\(x\)</span>-axis (in this case from 0 s to 5 s) and provide an <span class="math notranslate nohighlight">\(x\)</span>-axis label. The last command removes the <span class="math notranslate nohighlight">\(y\)</span>-axis tick marks since they don’t carry any real information in this case.</p>
</div><p>In the plot of the spike train above each spike time corresponds to a dot at a <span class="math notranslate nohighlight">\(y\)</span>-axis value of 1. The value on the <span class="math notranslate nohighlight">\(y\)</span>-axis is arbitrary. We could have chosen to use a <span class="math notranslate nohighlight">\(y\)</span>-axis value of 2 or -100 or 412. What matters is the <span class="math notranslate nohighlight">\(x\)</span>-axis, which indicates the time at which each spike occurs in the 5 s interval.</p>
<p>To compare the spiking in the low- and high-light conditions, we can plot both in the same figure:
<a id="fig:8.2b"></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">,</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">),</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>  <span class="c1"># Plot the low-light condition spikes</span>
<span class="n">plot</span><span class="p">(</span><span class="n">SpikesHigh</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">SpikesHigh</span><span class="p">),</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>  <span class="c1"># ... and the high-light condition spikes </span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>              <span class="c1"># Display times 0 to 5 s on the x-axis</span>
<span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>              <span class="c1"># ... and set the y-axis limits</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [s]&#39;</span><span class="p">)</span>            <span class="c1"># ... label the x-axis</span>
<span class="n">legend</span><span class="p">({</span><span class="s1">&#39;Low&#39;</span><span class="p">,</span> <span class="s1">&#39;High&#39;</span><span class="p">})</span>   <span class="c1"># ... show a legend</span>
<span class="n">yticks</span><span class="p">([])</span>                <span class="c1"># ... remove y-axis ticks</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_31_0.png" src="_images/08_31_0.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> What’s happening in the second line of this code segment?</p>
<p><strong>A.</strong> The second line of this code segment is similar to the first line, but it plots the data for the high ambient light condition. The first input to the <code class="docutils literal notranslate"><span class="pre">plot</span></code> function is the variable <code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code>. The second input to <code class="docutils literal notranslate"><span class="pre">plot</span></code> is a function; here we’re creating an array of 1s, this time with dimensions to match the variable <code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code>. Notice that we multiply this array by a scalar value of 2; this command acts to create a vector of 2s with the same dimensions as the vector <code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code>. The last input to <code class="docutils literal notranslate"><span class="pre">plot</span></code> indicates to display the data using another dot symbol. To summarize, here we’re calling the <code class="docutils literal notranslate"><span class="pre">plot</span></code> command to display</p>
<ul class="simple">
<li><p>x-axis values: spike times in the high ambient light condition</p></li>
<li><p>y-axis values: 2.</p></li>
</ul>
</div><div class="question">
<p><strong>Q.</strong> Explain why the following command fails to execute:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>plot(SpikesLow, ones_like(SpikesHigh), &#39;.&#39;)
</pre></div>
</div>
</div><p>With the data visualized in this way, we’re now able to ask an interesting question: What structure do you notice in the two spike trains? At first glance, your answer might be “not much.” Spikes occur fairly regularly throughout the 5 s interval under both conditions. Perhaps a careful visual inspection suggests there are fewer spikes in the low-light than in the high-light condition. But the spike times themselves do not seem to be directly comparable between these conditions. Often, when we examine data from a stimulus response experiment, we expect to see regions where spiking activity increases or decreases as a function of a changing stimulus. In this case, the stimulus is the ambient light level, which remains constant over the entire experiment. How else can we analyze these data and identify differences in the spiking activity (if any) between the two conditions?</p>
<div class="question">
<p><strong>Q.</strong> Up to now, we’ve plotted a 5 s interval of data that begins at time 0 s. Through visual inspection, do you find similar conclusions for other 5 s intervals chosen from the data?</p>
</div><p><a class="reference external" href="#top">Back to top</a></p>
<p><a id="isi"></a></p>
<div class="section" id="examining-the-interspike-intervals">
<h3>Examining the Interspike Intervals<a class="headerlink" href="#examining-the-interspike-intervals" title="Permalink to this headline">¶</a></h3>
<p>So far, we have examined the long-term structure of the spiking over multiple seconds. Let’s now focus on the short-term structure that occurs within a single second or less. Instead of plotting 5 s of spike train data, let’s plot an interval of 1 s:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">,</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">),</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>        <span class="c1"># Plot the low-light condition spikes</span>
<span class="n">plot</span><span class="p">(</span><span class="n">SpikesHigh</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">SpikesHigh</span><span class="p">),</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>  <span class="c1"># ... and the high-light condition spikes </span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>              <span class="c1"># Display times 10 to 11 s on the x-axis</span>
<span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>                <span class="c1"># ... and set the y-axis limits</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [s]&#39;</span><span class="p">)</span>              <span class="c1"># ... label the x-axis</span>
<span class="n">legend</span><span class="p">({</span><span class="s1">&#39;Low&#39;</span><span class="p">,</span> <span class="s1">&#39;High&#39;</span><span class="p">})</span>     <span class="c1"># ... show a legend</span>
<span class="n">yticks</span><span class="p">([])</span>                  <span class="c1"># ... remove y-axis ticks</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_38_0.png" src="_images/08_38_0.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> The code above was copied and pasted from the previous section with one minor update to change the time interval. What adjustments did we make to the code so that we see an interval of 1 s instead of 5 s?</p>
</div><p>Inspecting smaller time intervals, you might notice bursts of spikes that cluster near each other in time, interspersed with longer periods that contain less spiking. These patterns of bursts and quiescence look different between the low- and high-light stimuli. Visual inspection is an important tool, but we would like a quantitative result. How might we compare this fine temporal structure in the two conditions?</p>
<p>One approach to further characterizing the differences in spiking between the two conditions is to transform the data. One of the most useful transformations focuses on the waiting times between the spikes, or interspike intervals (ISIs), instead of the spike times themselves. We can compute the ISIs for the two conditions as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ISIsLow</span> <span class="o">=</span> <span class="n">diff</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">)</span>    <span class="c1"># Compute ISIs in the low-light condition</span>
<span class="n">ISIsHigh</span> <span class="o">=</span> <span class="n">diff</span><span class="p">(</span><span class="n">SpikesHigh</span><span class="p">)</span>  <span class="c1"># Compute ISIs in the high-light condition</span>
</pre></div>
</div>
</div>
</div>
<div class="question">
<p><strong>Q.</strong> How do these commands represent the ISIs of the data?</p>
<p><strong>A.</strong> Let’s focus on the first command, which defines the variable <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code>. Here, we use the function <code class="docutils literal notranslate"><span class="pre">diff()</span></code> with input <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code>. If you have not seen the command <code class="docutils literal notranslate"><span class="pre">diff()</span></code> before, look it up using <code class="docutils literal notranslate"><span class="pre">diff()?</span></code>. Briefly, the <code class="docutils literal notranslate"><span class="pre">diff()</span></code> command computes the difference between adjacent elements of the input. In this case, the vector <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> represents the times at which spikes occur. Therefore, the difference between adjacent elements of <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> produces the time interval or waiting time between successive spikes. To further explore the concept of an ISI, let’s write the spike times as a vector,</p>
<div class="math notranslate nohighlight">
\[
  v = {t_1, t_2, t_3, ..., T_N}, 
  \tag{2}
\]</div>
<p>where <span class="math notranslate nohighlight">\(t_i\)</span> is the time of the <span class="math notranslate nohighlight">\(i^{th}\)</span> spike. The difference between the first two adjacent elements of <span class="math notranslate nohighlight">\(v\)</span> is</p>
<div class="math notranslate nohighlight">
\[
  t_2 - t_1 \, .
  \tag{3}
\]</div>
<p>By convention, the <code class="docutils literal notranslate"><span class="pre">diff()</span></code> function subtracts the first element from the second. In words, this difference represents the time of the second spike (<span class="math notranslate nohighlight">\(t_2\)</span>) minus the time of the first spike (<span class="math notranslate nohighlight">\(t_1\)</span>), or the first interspike interval in the data. The difference between the next two adjacent elements of <span class="math notranslate nohighlight">\(v\)</span> is</p>
<div class="math notranslate nohighlight">
\[
  t_3 - t_2 \, ,
  \tag{4}
\]</div>
<p>which is the second ISI, and so on. In this way, <code class="docutils literal notranslate"><span class="pre">diff()</span></code> converts the spike times in the vector <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> into interspike intervals saved in the variable <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code>.</p>
</div><div class="question">
<p><strong>Q.</strong> Consider the variables <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code> and <code class="docutils literal notranslate"><span class="pre">ISIsHigh</span></code>. How do the sizes of these variables compare to the sizes of the corresponding spike trains <code class="docutils literal notranslate"><span class="pre">SpikesLow</span></code> and <code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code>, respectively? <em>Hint:</em> Given <span class="math notranslate nohighlight">\(N\)</span> spikes, how many ISIs must occur?</p>
</div><p>The variables <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code> and <code class="docutils literal notranslate"><span class="pre">ISIsHigh</span></code> are vectors, and we can visualize these vectors using the same tools we’ve applied to visualize vectors in other scenarios. For example, we may simply plot these vectors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_45_0.png" src="_images/08_45_0.png" />
</div>
</div>
<p>The x-axis is the vector index, which ranges from 1 to the length of the vector <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code>. The y-axis is the value of the ISI at each index. We see that the ISI values range from small times (less than 0.05 s) to large times (over 0.4 s). In this way, the visualization provides some insight into the ISI values for the low-light condition.</p>
<div class="question">
<p><strong>Q.</strong> Plot the ISI vector for the high-light condition and compare it to the ISI vector for the low-light condition. What similarities and differences do you notice in the ISIs from the two conditions?</p>
</div><div class="question">
<p><strong>Q.</strong> What is the smallest ISI you expect to observe for a neuron? Would you be surprised to find an ISI of less than 1 second? of less than 1 millisecond? of less than 1 nanosecond?</p>
</div><p>Plots of the ISI vectors provide some information about the data (e.g., the approximate range of the ISI values), but there’s more insight to be gained. To that end, let’s now implement another approach to visualizing these types of data: the <a href="https://en.wikipedia.org/wiki/Histogram" rel="external">histogram</a>. The idea of a histogram is to count the number of occurrences of each value in the data. In this case, we count the number of times we observe an ISI value in different bins of time. Let’s define the time bins for the histogram. Inspection of the ISI data for the low-light condition reveals values that range from near 0 s to over 0.4 s. Therefore, we choose the following time bins:</p>
<p>Bin 0 [0.00 0.01]</p>
<p>Bin 1 [0.01 0.02]</p>
<p>Bin 2 [0.02 0.03]</p>
<p>Bin 3 [0.03 0.04]</p>
<p>Bin 4 [0.04 0.05]</p>
<p>Bin 5 [0.05 0.06]</p>
<p>Bin 6 [0.06 0.07]</p>
<p>…</p>
<p>Bin N [0.49 0.50]</p>
<p>The bins begin at time 0 s and end at time 0.5 s, with a bin size of 0.01 s. The purpose of the histogram is to count the number of times the data values fall into each bin. Notice that we’ve chosen the range of bins to extend beyond the observed range of data <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code>; that’s fine, and we expect to count no values in the bins near 0.5 s. To further explore this counting process, let’s examine the first eight values of the data <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code>:</p>
<div class="python-note">
<p>Recall that Python uses <em>zero-based indexing</em>. This means that elements in arrays are numbered starting with 0, which is why we labeled the first bin “Bin 0” instead of “Bin 1”.</p>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ISIsLow</span><span class="p">[:</span><span class="mi">8</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([0.04098354, 0.02902169, 0.00746714, 0.05205904, 0.05553601,
       0.06204051, 0.02267623, 0.02132764])
</pre></div>
</div>
</div>
</div>
<p>We see that the first value of <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code> is approximately 0.0410. In which bin does this value belong? Examining the list of bins, we find that <code class="docutils literal notranslate"><span class="pre">ISIsLow[0]</span></code> lies in bin 4, so we increment the number of counts in bin 4 by 1. The second value of the vector <code class="docutils literal notranslate"><span class="pre">ISIsLow[1]</span></code> <span class="math notranslate nohighlight">\(\approx\)</span> 0.0290 lies in bin 2, so we increment the number of counts in bin 2 by 1. The third value, <code class="docutils literal notranslate"><span class="pre">ISIsLow[2]</span></code> <span class="math notranslate nohighlight">\(\approx\)</span> 0.0075, lies in bin 0, so we increment the number of counts in bin 0 by 1. The fourth value, <code class="docutils literal notranslate"><span class="pre">ISIsLow[4]</span></code> <span class="math notranslate nohighlight">\(\approx\)</span> 0.0521, lies in bin 5, so we increment the number of counts in bin 5 by 1. And the fifth value, <code class="docutils literal notranslate"><span class="pre">ISIsLow[4]</span></code> <span class="math notranslate nohighlight">\(\approx\)</span> 0.0555, also lies in bin 5, so we again increment the number of counts in bin 5 by 1.</p>
<div class="question">
<p><strong>Q.</strong> At this point, for the first five entries of the vector <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code>, how many counts are there in each bin?</p>
<p><strong>A.</strong> We find for the first five ISIs in the low-light condition, zero counts in all bins except</p>
<p>Bin 0: 1 count</p>
<p>Bin 2: 1 count</p>
<p>Bin 4: 1 count</p>
<p>Bin 5: 2 counts</p>
<p>Notice that only four bins have counts and that bin 5 has two counts; for the first five ISIs in the low-light condition, we observe two ISIs in the interval (0.05, 0.06).</p>
</div><div class="question">
<p><strong>Q.</strong> Repeat the binning procedure for the first eight ISIs observed in the high-light condition. Which bins have 1 or more counts for the first eight ISI values? What is the number of counts in each of these bins?</p>
</div><div class="question">
<p><strong>Q.</strong> Consider the first eight ISI values. In the previous question, you placed each of these values in a bin. Sum the counts across all bins. What do you find? Think about the value you compute; does the result make sense?</p>
</div><p>Of course, we’re free to choose any interval of bins for the histogram. In the preceding examples, we chose a bin size of 0.01 s = 10 ms. Based on our understanding of a neuron, we might instead choose to examine a smaller bin size, 0.001 s = 1 ms. Let’s do so now, and examine the histogram of all ISIs for the low-light condition. Of course, with enough patience, we could examine by hand each ISI value from the low-light condition and place each value in the correct 1 ms bin. However, this process would be time consuming and extremely error prone. Instead, the process of binning the ISI data is better done in Python. To create a histogram of all the ISI data in the low-light condition is straightforward:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">)</span>  <span class="c1"># Define the bins for the histogram</span>
<span class="n">hist</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>        <span class="c1"># Plot the histogram of the ISI data</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">])</span>            <span class="c1"># ... focus on ISIs from 0 to 150 ms</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;ISI [s]&#39;</span><span class="p">)</span>              <span class="c1"># ... label the x-axis</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Counts&#39;</span><span class="p">)</span>               <span class="c1"># ... and the y-axis</span>
<span class="n">title</span><span class="p">(</span><span class="s1">&#39;Low-light&#39;</span><span class="p">)</span>             <span class="c1"># ... give the plot a title</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_57_0.png" src="_images/08_57_0.png" />
</div>
</div>
<p>In the first line of this code segment, we define the bins. These bins start at time 0 s and end at time 0.499 s, and the size of each bin is 0.001 s. We then call the function <code class="docutils literal notranslate"><span class="pre">hist()</span></code> with two inputs: the first input is the variable we’d like to examine (here, <code class="docutils literal notranslate"><span class="pre">ISIsLow</span></code>, the ISIs in the low-light condition), and the second input is the bins. The function <code class="docutils literal notranslate"><span class="pre">hist()</span></code> computes the histogram and displays the result. By setting the <span class="math notranslate nohighlight">\(x\)</span>-axis limit with <code class="docutils literal notranslate"><span class="pre">xlim()</span></code>, we’ve chosen to examine the ISI values from 0 ms to 150 ms. We’ve also labeled the axes in the resulting figure. Notice that the <span class="math notranslate nohighlight">\(x\)</span>-axis indicates the binned ISI intervals, while the <span class="math notranslate nohighlight">\(y\)</span>-axis indicates the number of counts in each bin.</p>
<div class="question">
<p><strong>Q.</strong> Repeat this procedure to create a histogram of the ISI data in the high-light condition. Use the same bins we applied in the low-light condition (i.e., a bin size of 1 ms, extending from 0 s to 0.5 s). What do you find? <em>Hint:</em> Compare your answer to plot above.</p>
</div><p>Let’s visualize the distributions of ISIs in both conditions next to each other: <a id="fig:8-5"></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hist</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>        <span class="c1"># Plot the histogram of the low-light ISI data</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">])</span>            <span class="c1"># ... focus on ISIs from 0 to 150 ms</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Counts&#39;</span><span class="p">)</span>               <span class="c1"># ... label the y-axis</span>
<span class="n">title</span><span class="p">(</span><span class="s1">&#39;Low-light&#39;</span><span class="p">)</span>             <span class="c1"># ... give the plot a title</span>
<span class="n">show</span><span class="p">()</span>

<span class="n">hist</span><span class="p">(</span><span class="n">ISIsHigh</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>       <span class="c1"># Plot the histogram of the high-light ISI data</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">])</span>            <span class="c1"># ... focus on ISIs from 0 to 150 ms</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;ISI [s]&#39;</span><span class="p">)</span>              <span class="c1"># ... label the x-axis</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Counts&#39;</span><span class="p">)</span>               <span class="c1"># ... and the y-axis</span>
<span class="n">title</span><span class="p">(</span><span class="s1">&#39;High-light&#39;</span><span class="p">)</span>            <span class="c1"># ... give the plot a title</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_61_0.png" src="_images/08_61_0.png" />
<img alt="_images/08_61_1.png" src="_images/08_61_1.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> Describe the features of the two histograms. What features of the ISI distributions are similar for the two conditions? What features are most strikingly different?</p>
</div><p>In the ISI histogram of the low-light condition data, very few counts occur at small ISI values (near 0 ms) and high ISI values (beyond approximately 100 ms). Instead, the distribution of counts is broadly peaked in the approximate interval 5–20 ms.</p>
<div class="question">
<p><strong>Q.</strong> What does the ISI distribution reveal about the spiking activity in the low-light condition? From this ISI distribution, could you sketch a spike train consistent with these data?</p>
<p><strong>A.</strong> We conclude from the ISI distribution that many spikes are separated by time intervals 5–20 ms. So, we might be tempted to imagine near-periodic spiking with a period 5–20 ms:</p>
<p><a id="fig:8.6a"></a></p>
<p><img alt="Cartoon representation of spiking activity." src="_images/8-6a.png" /></p>
<p>However, the histogram contains additional structure beyond the single broad peak. Indeed, the histogram has a long tail, with counts extending up to 150 ms. Therefore, the intervals between spikes are varied. We often see ISIs in the 5–20 ms interval, but we also find much longer ISIs (e.g., from 50 to 150 ms). The structure of the ISI histogram is consistent with bursting activity, which consists of intervals of rapid spiking interspersed with quiescence:</p>
<p><a id="fig:8.6b"></a></p>
<p><img alt="Cartoon representation of spiking activity." src="_images/8-6b.png" /></p>
<p>The intervals of rapid spiking produce many shorter ISIs, and the longer intervals produce (typically fewer) longer ISIs. We may conceptualize a bursting neuron as having two time scales: fast and slow. From the shape of the histogram of the low-light condition, we conclude that the spike train data in the low-light condition are more consistent with bursting activity than with periodic, metronome-like spiking activity.</p>
</div><div class="question">
<p><strong>Q.</strong> What does the ISI distribution reveal about the spiking activity in the high-light condition? From this ISI distribution, could you sketch a spike train consistent with these data?</p>
</div><p>Let’s now consider the two ISI histograms representing the spiking activity from the two conditions. We note that both histograms show no ISI values below 0 ms. This is to be expected; the intervals between spikes cannot be negative. Both histograms also show broad peaks at 5–20 ms, indicating that a large number of short ISIs appear in the spike trains. In addition, both histograms possess long tails (i.e., counts of ISIs at larger bins, beyond 50 ms). A reasonable conclusion is that both neurons exhibit bursting activity, intervals of rapid spiking separated by periods of quiescence. However, a prominent difference exists between the ISI histograms in the two conditions. In the high-light condition, the proportion of small ISIs is much larger. The visualizations of the ISI histograms provide additional evidence of the similarities and differences in the spiking activity from the two conditions. We continue to investigate these two datasets—and build our scientific conclusions—in the next sections.</p>
<div class="question">
<p><strong>Q.</strong> We claim that the neuron exhibits bursting activity in both histograms. But clearly the two ISI histograms are different. How does the bursting activity differ in the low- and high-light conditions? <em>Hint:</em> Consider the impact of the large proportion of small ISIs in the high-light condition.</p>
</div><div class="question">
<p><strong>Q.</strong> So far, we’ve investigated two bin sizes: 10 ms and 1 ms. How do the shapes of the histograms above depend on the bin size used? Was 1 ms a good choice in this case? Why, or why not?</p>
</div><p><a class="reference external" href="#top">Back to top</a>
<a id="bsi"></a></p>
</div>
<div class="section" id="examining-binned-spike-increments">
<h3>Examining Binned Spike Increments<a class="headerlink" href="#examining-binned-spike-increments" title="Permalink to this headline">¶</a></h3>
<p>Another common approach to analyzing spiking data is to discretize time into bins of fixed width and count the number of events that occur in each time bin. The sequence of spike counts across all the bins is sometimes called the increment process for the spike train. When the time bins are sufficiently small, say, 1 ms for typical spike train data, the resulting increment process is just a sequence of zeros and ones. In this case, the time bins are so small that the probability of more than one spike occurring in each bin is zero or negligibly small.<sup><abbr title="The biophysical mechanisms that produce a spike support this statement. After generating a spike, the neuron experiences a refractory period typically lasting a few milliseconds, in which generating a subsequent spike is very unlikely.">note</abbr></sup> Each tiny time bin then contains a spike (and we assign that bin a value of 1) or does not (and we assign that bin a value of 0). This idea of representing the spike train as a sequence of zeros and ones for small bin increments will be important when we build statistical models of the spike trains in a <a href="09" rel="local">later notebook</a>. In this section, we compute the increment process with multiple bin sizes in order to characterize the amount of variability in the spiking data and to examine temporal dependencies between spikes.</p>
<p>Let’s bin the spike train data of the low-light condition into time bins of size 50 ms. To do so, we make use of the function <code class="docutils literal notranslate"><span class="pre">histogram()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">time_bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>                       <span class="c1"># Define the time bins</span>
<span class="n">IncrementsLow50</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">)</span>  <span class="c1"># ... and compute a histogram of the data</span>
<span class="n">plot</span><span class="p">(</span><span class="n">time_bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">IncrementsLow50</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>               <span class="c1"># Plot the resulting counts over time</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [s]&#39;</span><span class="p">)</span>                                       <span class="c1"># ... with axes labeled</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of Spikes&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_70_0.png" src="_images/08_70_0.png" />
</div>
</div>
<p>Notice that, in this case, we use the function <code class="docutils literal notranslate"><span class="pre">histogram()</span></code> in a new way. Instead of simply generating a plot, we call the function with the output variable <code class="docutils literal notranslate"><span class="pre">IncrementsLow50</span></code>. This variable <code class="docutils literal notranslate"><span class="pre">IncrementsLow50</span></code> is a vector containing the number of counts (i.e., the number of spikes) in each 50 ms increment. The time bins (<code class="docutils literal notranslate"><span class="pre">time_bins</span></code>, the second input to the function <code class="docutils literal notranslate"><span class="pre">histogram</span></code>) is a vector containing the bin locations in time. In this case, the time bins start at time 0 s and end at time 30 s, with 0.05 s between bins. The variable name <code class="docutils literal notranslate"><span class="pre">IncrementsLow50</span></code> is quite descriptive. It reminds us that the variable represents the increments process in the low-light condition with a time bin of 50 ms.</p>
<div class="python-note">
<p>A descriptive choice of variable name is often useful.</p>
</div><div class="question">
<p><strong>Q.</strong> What can you say about the spike train data based on the increment process that we just plotted? Approximately how often do you observe a 50 ms increment with zero spikes? With four spikes?</p>
</div><p>One question that arises quite often is how variable these binned counts are. To illustrate this variability, let’s consider two scenarios. In the first, consider a neuron that fires perfectly regularly, like a metronome. In this case, we expect the number of spikes in each time bin to be nearly identical. On the other hand, consider the scenario of a neuron that fires in irregular bursts. In this case, we expect much more variability in the number of spikes in each time bin, depending on whether a time bin contained a burst of spikes or a quiet period. To characterize this variability, a standard measure to compute is the sample <strong>Fano factor (FF)</strong>. It’s easy to define the Fano factor: FF is the sample variance of the increment process divided by the sample mean of the increment process. The implementation of FF in Python is also relatively simple:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">FF50Low</span> <span class="o">=</span> <span class="n">IncrementsLow50</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="o">/</span> <span class="n">IncrementsLow50</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;FF50Low =&#39;</span><span class="p">,</span> <span class="n">FF50Low</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>FF50Low = 0.7164927285225824
</pre></div>
</div>
</div>
</div>
<div class="question">
<p><strong>Q.</strong> How do we interpret this FF value?</p>
</div><p>To answer that question, we need to introduce the concept of a <strong>Poisson process</strong>. A Poisson process is a model for a spiking process for which each spike occurrence is independent of every other spike occurrence. In other words, the probability of a neuron spiking at any instant does not depend on when the neuron fired (or did not fire) previously. A useful way to conceptualize this process is as a coin flip. For example, consider the following outcome of 20 coin flips:</p>
<p>HTHTTTHTTTTTHHHHHHTH</p>
<p>where H indicates heads, and T indicates tails.</p>
<div class="question">
<p><strong>Q.</strong> Based on your intuitive knowledge of a coin flip, does the result of a chosen coin flip depend on any other coin flip?</p>
<p><strong>A.</strong> No. Consider, for example, the fifth coin flip. In the example outcome, the fifth coin flip resulted in T (tails). Does this result depend on the previous coin flip? on the next coin flip? on the first coin flip? on a future one-hundredth coin flip? In all cases, intuition suggests that it does not. Each coin flip is independent of every other coin flip. That’s the assumption we make in assuming a Poisson process as a model for spiking activity: each spike occurrence is independent of every other spike occurrence.</p>
</div><p>The Poisson process is rarely an accurate model for spike train data. Our biological knowledge reveals that the occurrence of a spike does depend on the occurrence of previous spikes (e.g., because of the refractory period of a neuron, we do not expect a spike to occur immediately after another spike). However, the Poisson process has many nice theoretical properties that make it a good model against which to compare the data. For example, for any Poisson process, the number of spikes in any time interval has a Poisson probability distribution for which the theoretical variance and mean are equal (see the <a class="reference external" href="#appendix">appendix</a> at the end of the notebook).</p>
<div class="math-note">
<p>The theoretical Fano factor for a Poisson process is exactly equal to 1.</p>
</div><p>When measuring the variability of the increments of a spike train, we typically compare it to the variability of a Poisson process. If we compute a Fano factor well below the value 1 for a particular set of increments, this suggests that the spiking is more regular than a Poisson process for the time scale at which the increments were binned. In this case, spiking activity in the past is influencing the neuron to spike in a more predictable manner in subsequent bins. If we compute a Fano factor well above the value 1, this suggests that the spiking is more variable than a Poisson process for the time scale at which the increments were binned.</p>
<p>For the 50 ms binned spikes in the low-light condition, we obtained a sample Fano factor value of 0.72, well below 1. We might therefore conclude that the spiking data in the low-light condition are more regular (i.e., more like a metronome) than we expect for a Poisson process.</p>
<div class="question">
<p><strong>Q.</strong> What can we conclude about the variability of the counts for the spiking data in the high-light condition?</p>
<p><strong>A.</strong> Repeating the analysis, we find that the sample Fano factor in the high-light condition is 1.78, well above 1. We might therefore conclude that the spiking data in the high-light condition are less regular than we expect for a Poisson process.</p>
</div></div>
<div class="section" id="does-the-observed-fano-factor-differ-from-1">
<h3>Does the observed Fano factor differ from 1?<a class="headerlink" href="#does-the-observed-fano-factor-differ-from-1" title="Permalink to this headline">¶</a></h3>
<p>The preceding results are somewhat unsatisfying. We claimed that in the low-light condition, the calculated Fano factor of 0.72 was well below 1. What if, instead, we calculated a Fano factor of 0.8; is that well below 1? Is a Fano factor of 0.9 well below 1? These questions highlight an important issue when drawing a conclusion from a Fano factor calculation: How far above or below the value of 1 does the calculated Fano factor have to be before we are confident that there is really a statistically significant difference in the variability from a Poisson process? After all, even if we had spiking from a true Poisson process, from one experiment to the next we would expect to find different values for the increments, and values for the sample Fano factor that fluctuate slightly above and below 1. Fortunately, a bit of statistical theory can help us out. It can be shown that the distribution of Fano factors that we might compute from a Poisson process follows a gamma distribution with shape parameter <span class="math notranslate nohighlight">\((N - 1)/2\)</span> and scale parameter
<span class="math notranslate nohighlight">\(2/(N - 1)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the number of time bins used in the Fano factor calculation [<a href="https://doi.org/10.1016/j.jneumeth.2010.04.012" rel="external">Eden &amp; Kramer, 2010</a>].</p>
<div class="question">
<p><strong>Q.</strong> What is the correct value of <span class="math notranslate nohighlight">\(N\)</span> for the increment process computed above and saved in the variable IncrementsLow50?</p>
<p><strong>A.</strong> We find in Python that</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>IncrementsLow50.shape
</pre></div>
</div>
<p>is 600. Therefore, N = 600. This makes sense; 600 time bins of 50 ms duration fit between 0 s and 30 s.</p>
</div><p>With the value of <span class="math notranslate nohighlight">\(N = 600\)</span> now determined, let’s plot the gamma distribution and investigate its shape:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gamma</span>   <span class="c1"># Import the gamma object from the SciPy stats toolbox</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">IncrementsLow50</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>   <span class="c1"># Determine number of time bins.</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>             <span class="c1"># Define the shape parameter of the gamma function</span>
<span class="n">scale</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>             <span class="c1"># ... and the scale parameter </span>
<span class="n">FF</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span> <span class="c1"># Define possible FF values</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">FF</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> 
              <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>      <span class="c1"># ... compute gamma distribution,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">FF</span><span class="p">,</span><span class="n">Y</span><span class="p">);</span>                     <span class="c1"># ... and plot it</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fano Factor&#39;</span><span class="p">)</span>           <span class="c1"># ... with axes labeled</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">)</span>  
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_86_0.png" src="_images/08_86_0.png" />
</div>
</div>
<p>Notice that we’re evaluating the function <code class="docutils literal notranslate"><span class="pre">gamma.pdf()</span></code>, which returns as output the gamma probability density function. We provide three inputs to this function. The first specifies a range of Fano factors to investigate (here we choose Fano factors ranging from 0.5 to 1.5; we choose a large number of Fano factor values to make a smooth plot of the gamma distribution). The second and third inputs to the function specify the shape and scale parameters of the gamma distribution.</p>
<p>When <span class="math notranslate nohighlight">\(N\)</span> is large, as it is here, the gamma distribution looks like a normal distribution (i.e., like a bell-shaped curve). We can use this distribution to construct an interval where we would expect the Fano factor to lie if the data were generated by a Poisson process. More specifically, if the data were generated by a Poisson process, then we would expect the Fano factor to lie in the 95% confidence interval around the value of 1. Let’s construct this 95% confidence interval:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">gamma</span><span class="o">.</span><span class="n">ppf</span><span class="p">([</span><span class="o">.</span><span class="mi">025</span><span class="p">,</span> <span class="o">.</span><span class="mi">975</span><span class="p">],</span> <span class="n">shape</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([0.88985257, 1.11648138])
</pre></div>
</div>
</div>
</div>
<p>In this case, we use the function <code class="docutils literal notranslate"><span class="pre">gamma.ppf()</span></code> to compute the gamma inverse cumulative distribution function (or percentiles). The first input specifies the boundaries of the probabilities of interest, which range from 2.5% to 97.5%, to encompass 95% of the probability mass around the value of 1. The next two inputs specify the shape and scale parameters of the gamma distribution. Evaluating this line of code, we find the interval (0.890, 1.116). Therefore, if we observed a true Poisson process with N = 600 bins and computed the Fano factor, we would not be surprised to find values between 0.890 and 1.116. However, the observed Fano factor for an increment process with 50 ms bins in the low-light condition is well outside of this range; this result suggests that it is very unlikely that these data were generated by a Poisson process. Instead, it’s more likely that these data were generated by a process with less variability in the low-light condition (FF = 0.72).</p>
<div class="question">
<p><strong>Q.</strong> Consider the Fano factor for the high-light condition. Do you believe these data were generated by a Poisson process? Why, or why not?</p>
<p><strong>A.</strong> We found for the high-light condition a Fano factor of 1.78 (again using an increment process with 50 ms bins). This calculated value is well above the interval expected for a Poisson process. We therefore reject the hypothesis that these data were generated by a Poisson process. Instead, we observe more variability in the high-light condition than expected for a Poisson process (with <span class="math notranslate nohighlight">\(N = 600\)</span>).</p>
</div><div class="question">
<p><strong>Q.</strong> How do the results for the Fano factor change in each condition with different choices for the bin size of the increment process (e.g., 25 ms, 100 ms, 500 ms)? Note that by changing the bin size, you also change <span class="math notranslate nohighlight">\(N\)</span>. <em>Challenge</em>: See if you can write a function that takes the data and desired binwidth as input and returns the Fano factor and 95% confidence interval.</p>
</div><p><a class="reference external" href="#top">Back to top</a>
<a id="autocorrelations"></a></p>
</div>
<div class="section" id="computing-autocorrelations-for-the-increments">
<h3>Computing Autocorrelations for the Increments<a class="headerlink" href="#computing-autocorrelations-for-the-increments" title="Permalink to this headline">¶</a></h3>
<p>Another way to characterize the history dependence structure of a spike train is with the <em>autocorrelation</em> function of the increments. A correlation coefficient describes the degree of linear dependence between any two variables. The value of the correlation ranges from -1 to 1. A correlation value of -1 indicates a perfect linear relation between the two variables with a negative slope. A value of 0 indicates no linear relation between the two variables. And a value of 1 indicates a perfect linear relation between the two variables with a positive slope. Any other value indicates that one variable can be predicted using a linear function of the other, but that prediction will be imperfect; the closer the value is to $\pm$1, the better the prediction will be. The sign of the coefficient indicates the slope of the linear relation. The following figure shows scatterplots for a variety of possible relations between two variables, and the values of the correlation coefficients.</p>
<p><img alt="Correlation values for example relations between two variables." src="_images/8-9.png" /></p>
<p>Mathematically, the formula for the sample autocorrelation at a lag <span class="math notranslate nohighlight">\(L\)</span> is
<a id="eq:5"></a></p>
<div class="math notranslate nohighlight">
\[
  \rho_{xx}[L] = \dfrac{
  \sum_{i=1}^{N - L}
  (x_i - \bar{x})(x_{i+L} - \bar{x})
  }
  {
  \sum_{i=1}^{N}(x_i - \bar{x})^2
  }
  \tag{5}
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_i\)</span> is the <span class="math notranslate nohighlight">\(i^{th}\)</span> data point, and <span class="math notranslate nohighlight">\(\bar{x}\)</span> is the sample mean of the data over index <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>To gain some intuition for the autocorrelation, let’s consider the following relatively simple increment process:</p>
<p><a id="fig:8-10a"></a></p>
<p><img alt="Example data for visual inspection of autocorrelation of an increment process." src="_images/8-10a.png" /></p>
<p>Our goal is to understand the autocorrelation of these data, labeled <span class="math notranslate nohighlight">\(x\)</span>. From visual inspection of the figure, we conclude that the data <span class="math notranslate nohighlight">\(x\)</span> have mean 0, so that <span class="math notranslate nohighlight">\(\overline x = 0\)</span>; note that the data appear to oscillate between equal and opposite values over time. For simplicity, let’s focus on the numerator of equation (<a href="#eq:5" class="thumb">5<span><img src="imgs/eq5.png"></span></a>). At lag zero (i.e., <span class="math notranslate nohighlight">\(L = 0\)</span>), the numerator of (<a href="#eq:5" class="thumb">5<span><img src="imgs/eq5.png"></span></a>) tells us to multiply the data by themselves at each time index, and then sum the product. To visualize this multiplication and sum, consider multiplying the data in the figure above by the following data at each index in time and then summing the result.</p>
<p><a id="fig:8-10b"></a></p>
<p><img alt="Example data for visual inspection of autocorrelation of an increment process." src="_images/8-10b.png" /></p>
<div class="question">
<p><strong>Q.</strong> What is the value of this sum?</p>
<p><strong>A.</strong> We can’t answer this question without knowing the values of <span class="math notranslate nohighlight">\(x\)</span>. However, we can deduce the sign and relative size of the sum. At a time index where <span class="math notranslate nohighlight">\(x\)</span> is positive, the product is positive; and at a time index where <span class="math notranslate nohighlight">\(x\)</span> is negative, the product is still positive. So, the product at each time index will always be positive or zero. Therefore, we expect the sum to be a positive number. And if we add many terms, we expect this sum to be large. So, we may conclude that the value of this sum will be a large, positive number. Note that this number is the numerator of the autocorrelation. At <span class="math notranslate nohighlight">\(L = 0\)</span>, the numerator equals the denominator in (<a href="#eq:5" class="fig">5<span><img src="imgs/eq5.png"></span></a>) and the autocorrelation at lag zero is 1.</p>
</div><p>Let’s consider the numerator of the autocorrelation (<a href="#eq:5" class="fig">5<span><img src="imgs/eq5.png"></span></a>) for a small positive lag (i.e., <span class="math notranslate nohighlight">\(L &gt; 0\)</span>). We can think of the small positive lag as shifting the data <span class="math notranslate nohighlight">\(x\)</span> a little bit to the right:</p>
<p><a id="fig:8-10c"></a></p>
<p><img alt="Example data for visual inspection of autocorrelation of an increment process." src="_images/8-10a.png" /></p>
<p><img alt="Example data for visual inspection of autocorrelation of an increment process." src="_images/8-10c.png" /></p>
<p>Now, to compute the numerator of the autocorrelation, we multiply <span class="math notranslate nohighlight">\(x\)</span> by a shifted version of <span class="math notranslate nohighlight">\(x\)</span> at each time index and then sum the result. In this case, we find some indices where the product of <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(x_{i+L}\)</span> is positive, and some indices where the product of <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(x_{i+L}\)</span> is negative; an example of an index where the product is negative is indicated above by the black circle. Visual comparison of the two plots suggests that the product will be positive more often then negative. Therefore, we expect the sum of these products to still be positive, although not as large as we found for the <span class="math notranslate nohighlight">\(L = 0\)</span> case. You may have noticed some points where the data do not overlap, at the far right and far left of the figure. At these locations, the product is zero.</p>
<p>Let’s return to the spike train data of interest here, recorded in the low- and high-light conditions. For the corresponding spike train increments, the autocorrelation at a particular lag describes the relation between the spike counts in different bins separated by that lag. The autocorrelation function describes the autocorrelation across a range of lags over which we are interested. Given our visualizations of the ISI histograms (<a href="#fig:8-5" class="fig">figure<span><img src="imgs/8-5.png"></span></a>), we might expect relations between spiking events to extend up to 200 ms.</p>
<p>Let’s compute the autocorrelation for increment processes deduced from the spike train data in the low-light condition. We compute the autocorrelation of the 50 ms increment process for lags ranging from 0 to 200 ms. We need only three lags to cover this range; lag 1 covers 50–100 ms, lag 2 covers 100–150 ms, and lag 3 covers 150–200 ms. We can define a function to compute the autocorrelation using the function <code class="docutils literal notranslate"><span class="pre">correlate()</span></code> from the NumPy module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">autocorr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lags</span><span class="p">):</span>
    <span class="n">xcorr</span> <span class="o">=</span> <span class="n">correlate</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="s1">&#39;full&#39;</span><span class="p">)</span>  <span class="c1"># Compute the autocorrelation</span>
    <span class="n">xcorr</span> <span class="o">=</span> <span class="n">xcorr</span><span class="p">[</span><span class="n">xcorr</span><span class="o">.</span><span class="n">size</span><span class="o">//</span><span class="mi">2</span><span class="p">:]</span> <span class="o">/</span> <span class="n">xcorr</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>               <span class="c1"># Convert to correlation coefficients</span>
    <span class="k">return</span> <span class="n">xcorr</span><span class="p">[:</span><span class="n">lags</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>                                     <span class="c1"># Return only requested lags</span>
    
<span class="n">autocorr</span><span class="p">(</span><span class="n">IncrementsLow50</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([1.        , 0.03894992, 0.07055464, 0.04431669])
</pre></div>
</div>
</div>
</div>
<p>Our new function <code class="docutils literal notranslate"><span class="pre">autocorr()</span></code> takes two inputs. The first input is the data for which we want to compute the autocorrelation, in this case, the increment process for the low-light condition with 50 ms time bins. The second input is the number of lags to compute. Within the function, we scale the raw autocorrelation so that we instead see correlation coefficients, which range from -1 to 1. Notice that we subtract from <code class="docutils literal notranslate"><span class="pre">IncrementsLow50</span></code> the mean of this variable before computing the autocorrelation. This command outputs a vector with four numerical values corresponding to the autocorrelation at lag indices 0 through 3. The autocorrelation at negative lags is mathematically identical to the autocorrelation at the equivalent positive lags, which is why we exclude them in the third line of the function definition.</p>
<div class="question">
<p><strong>Q.</strong> Examine the numerical values returned by <code class="docutils literal notranslate"><span class="pre">autocorr()</span></code>. What do you find?</p>
<p><strong>A.</strong> As expected, the autocorrelation at zero lag is exactly equal to 1; the data matches itself at lag 0. At lag 1, corresponding to 50–100 ms, the autocorrelation value is 0.04. This positive correlation value indicates that when the number of spikes in one bin is higher than expected, the number of spikes in the next bin tends to be higher than expected. Similarly, when the number of spikes in one bin is lower than expected, the number of spikes in the next bin will also tend to be lower than expected. This effect is small, however, since the autocorrelation is near zero. At lag 2, corresponding to 100–150 ms, the autocorrelation value of 0.07 is again small and positive. At lag 3, corresponding to 150–200 ms, the autocorrelation value remains small and positive at a value of 0.04.</p>
</div><div class="question">
<p><strong>Q.</strong> How do we know whether these autocorrelation values are statistically significant?</p>
<p><strong>A.</strong> This can be a difficult question when <span class="math notranslate nohighlight">\(N\)</span> is small (less than 30), but for larger <span class="math notranslate nohighlight">\(N\)</span> we can approximate a confidence interval about the correlation coefficient using a normal approximation with standard deviation <span class="math notranslate nohighlight">\(1/\sqrt N\)</span>. In this case, any correlation value exceeding <span class="math notranslate nohighlight">\(\pm2/\sqrt N\)</span> is unlikely to be generated by chance and likely reflects real dependence structure. For the increment process considered here, <span class="math notranslate nohighlight">\(N = 599\)</span>, and the significance bound is <span class="math notranslate nohighlight">\(\pm 0.08\)</span>. We conclude that none of the lags has significant autocorrelation.</p>
</div><p>If we are particularly interested in the fine-scale temporal dependence structure of the spikes, we would do better to compute the autocorrelation function for more finely binned intervals. To that end, let’s repeat the autocorrelation analysis for an increment process that uses 1 ms bins. We first compute a new increment process and then apply the <code class="docutils literal notranslate"><span class="pre">autocorr()</span></code> function to this process.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">time_bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>                    <span class="c1"># Define the time bins</span>
<span class="n">IncrementsLow1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">SpikesLow</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">)</span> <span class="c1"># ... compute the histogram to create increment process</span>
<span class="n">ACFLow</span> <span class="o">=</span> <span class="n">autocorr</span><span class="p">(</span><span class="n">IncrementsLow1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>                 <span class="c1"># ... and the autocorrelation</span>
</pre></div>
</div>
</div>
</div>
<div class="question">
<p><strong>Q.</strong> What is the size of the output variable <code class="docutils literal notranslate"><span class="pre">ACFLow</span></code>? How does this size correspond to the lags?</p>
<p><strong>A.</strong> <code class="docutils literal notranslate"><span class="pre">ACFLow</span></code> is a vector with dimensions 1 <span class="math notranslate nohighlight">\(\times\)</span> 101. The 101 values correspond to lag indices 0 to 100 (or lag times 0 ms to 100 ms).</p>
</div><p>In order to examie history dependence going back 100 ms, we need 100 lags (because each lag index corresponds to 1 ms). There are now too many values to examine them printed one by one on the screen, so instead we construct a plot of the autocorrelation function with lag on the <span class="math notranslate nohighlight">\(x\)</span>-axis and correlation on the <span class="math notranslate nohighlight">\(y\)</span>-axis. Let’s also include in this figure two approximate significance lines at <span class="math notranslate nohighlight">\(\pm2/\sqrt N\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot</span><span class="p">(</span><span class="n">ACFLow</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>                  <span class="c1"># Plot autocorrelation vs lags,</span>
<span class="n">N1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">IncrementsLow1</span><span class="p">)</span>           <span class="c1"># ... compute the sample size</span>
<span class="n">sig</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">N1</span><span class="p">)</span>              <span class="c1"># ... and the significance level</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="n">sig</span><span class="p">,</span> <span class="n">sig</span><span class="p">],</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>   <span class="c1"># ... and plot the upper and lower significance lines</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="n">sig</span><span class="p">,</span> <span class="o">-</span><span class="n">sig</span><span class="p">],</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>                 <span class="c1"># ... set x-limits</span>
<span class="n">ylim</span><span class="p">([</span><span class="o">-.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">])</span>                <span class="c1"># ... and y-limits</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [ms]&#39;</span><span class="p">)</span>                <span class="c1"># ... with axes labeled</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Autocorrelation&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_106_0.png" src="_images/08_106_0.png" />
</div>
</div>
<p>We see that the two approximate significance lines at <span class="math notranslate nohighlight">\(\pm2/\sqrt N\)</span> suggest significant negative correlation structure is present up to about <span class="math notranslate nohighlight">\(6\)</span> ms. This reflects the refractory period of the neuron: if you observed a spike in the previous 6 ms, you are less likely to observe a spike in the next few milliseconds. Beyond this point, the values of the autocorrelation mostly remain between the two significance bounds.</p>
<div class="math-note">
<p><strong>Alert!</strong> We are using these significance bounds here for exploratory purposes. We are not performing a rigorous statistical test for significance of the autocorrelation at every lag.</p>
</div><p>If we choose to perform a rigorous statistical test for the significance of the autocorrelation, we would face the multiple comparisons problem. Briefly, if we perform many independent tests, and each has a 5% chance of reaching significance by chance, then the probability that any of these tests reaches significance by chance can be very large. If we wanted to perform many tests, we would need to control for multiple comparisons by adjusting the significance level so that the probability of any test being significant by chance is small. In the plot above, the significance lines are not corrected for multiple comparisons. Therefore, we accept that some of the correlation values that exceed these bounds may occur by chance. However, it is still very unlikely that all the significant correlations we observed from 1 to 6 ms are occurring purely by chance.</p>
<p>Now that we’ve computed and interpreted the autocorrelation function for the low-light condition, let’s compare it to the autocorrelation in the high-light condition. We repeat our previous commands using the <code class="docutils literal notranslate"><span class="pre">SpikesHigh</span></code> data values and choosing a time bin of 1 ms:
<a id=fig:8-12></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">IncrementsHigh1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">SpikesHigh</span><span class="p">,</span> <span class="n">time_bins</span><span class="p">)</span> <span class="c1"># Compute the histogram to create increment process</span>
<span class="n">ACFHigh</span> <span class="o">=</span> <span class="n">autocorr</span><span class="p">(</span><span class="n">IncrementsHigh1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>                 <span class="c1"># ... and the autocorrelation.</span>
<span class="n">plot</span><span class="p">(</span><span class="n">ACFHigh</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>                                       <span class="c1"># Plot the autocorrelation,</span>
<span class="n">sig</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">IncrementsHigh1</span><span class="p">))</span>                  <span class="c1"># ... compute and plot the significance level,</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="n">sig</span><span class="p">,</span> <span class="n">sig</span><span class="p">],</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>                               
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="n">sig</span><span class="p">,</span> <span class="o">-</span><span class="n">sig</span><span class="p">],</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>                                       <span class="c1"># ... and set the plot limits,</span>
<span class="n">ylim</span><span class="p">([</span><span class="o">-.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">])</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [ms]&#39;</span><span class="p">)</span>                                      <span class="c1"># ... with axes labeled.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Autocorrelation&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_110_0.png" src="_images/08_110_0.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> Consider the autocorrelation of the spike train data in the high-light condition shown above. What do you observe? How do the autocorrelations differ in the two conditions?</p>
<p><strong>A.</strong> We find in the high-light condition significant correlation structure going all the way out to about 50 ms. Once again, we see refractoriness reflected in the negative autocorrelation at a lag of 1 ms, but this lasts much less time than in the low-light condition. Instead, there is now significant positive correlation at intermediate lags (approximately 2–50 ms). This positive correlation at short time lags reflects the tendency of the neuron to fire in bursts with small ISIs in the high-light condition; after a spike, another spike is more likely to occur in the next 2–50 ms than in the subsequent 50–100 ms.</p>
</div><p>Now that we’ve visualized the autocorrelations in the two light conditions, we can ask an important related question: Are the differences in the autocorrelations between these two conditions real? To answer this, we compute the difference in the autocorrelation functions between the low- and high-light conditions at every lag. If we assume that the firing in each condition is independent, the significance bounds for this difference can be computed by adding the variance of the autocorrelation from each condition. The standard deviation of the autocorrelation for the low-light condition is <span class="math notranslate nohighlight">\(1/\sqrt{N_1}\)</span>, so the variance of the auto- correlation for the low-light condition is <span class="math notranslate nohighlight">\(1/N_1\)</span>. For the high-light condition, the variance of the autocorrelation is <span class="math notranslate nohighlight">\(1/N_2\)</span>. We plot the differenced autocorrelations and the significance bounds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">IncrementsHigh1</span><span class="p">)</span>
<span class="n">ACFDiff</span> <span class="o">=</span> <span class="n">ACFHigh</span> <span class="o">-</span> <span class="n">ACFLow</span>                    <span class="c1"># Compute differences of autocorrelations</span>
<span class="n">plot</span><span class="p">(</span><span class="n">ACFDiff</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>                            <span class="c1"># ... and plot them</span>
<span class="n">sd</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">N1</span><span class="o">+</span><span class="mi">1</span><span class="o">/</span><span class="n">N2</span><span class="p">)</span>                       <span class="c1"># ... with significance bounds.</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sd</span> <span class="o">*</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sd</span> <span class="o">*</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>                            <span class="c1"># Set the plot limits and label the axes.</span>
<span class="n">ylim</span><span class="p">([</span><span class="o">-.</span><span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">])</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [ms]&#39;</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Autocorrelation difference&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_113_0.png" src="_images/08_113_0.png" />
</div>
</div>
<p>The results suggest significant differences in the autocorrelation between the two conditions at intermediate time lags (at approximately 2–50 ms). These are the same time lags we identified with bursting activity in the high-light condition. This suggests that the neuron fires with more intermediate ISIs in the bursting range in the high-light condition.</p>
<p><a class="reference external" href="#top">Back to top</a>
<a id="acISI"></a></p>
</div>
<div class="section" id="computing-autocorrelations-of-the-isis">
<h3>Computing Autocorrelations of the ISIs<a class="headerlink" href="#computing-autocorrelations-of-the-isis" title="Permalink to this headline">¶</a></h3>
<p>The autocorrelation of the increments indicates the amount of time for which there are dependencies in the spiking data. In the high-light condition, we found large correlation values extending out to approximately 50 ms. This could be a consequence of the influence of patterns of many spikes with shorter ISIs or of single spikes with longer ISIs. We can distinguish between these possibilities by looking at the autocorrelation of the sequence of ISIs. In this case, the lag represents the number of spikes in the past rather than the amount of time in the past. If the dependence is only due to the last spike, we expect the ISIs to be uncorrelated at any nonzero lag. This would necessarily be true for data from a Poisson process. If we see correlation between ISIs, this suggests that the data do not come from a Poisson process and that the past spiking has an influence over multiple spikes. To investigate this, let’s compute the autocorrelation of the sequence of ISIs for the low-light condition:
<a id="fig:8-14"></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ISI_ACF_Low</span> <span class="o">=</span> <span class="n">autocorr</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>  <span class="c1"># Compute and plot the autocorrelation of the low-light ISIs,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">ISI_ACF_Low</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">N3</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>                    <span class="c1"># ... with upper and lower significance lines.</span>
<span class="n">sd</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">N3</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sd</span> <span class="o">*</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">ISI_ACF_Low</span><span class="p">),</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>
<span class="n">plot</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sd</span> <span class="o">*</span> <span class="n">ones_like</span><span class="p">(</span><span class="n">ISI_ACF_Low</span><span class="p">),</span> <span class="s1">&#39;r:&#39;</span><span class="p">)</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>                    <span class="c1"># Set plot limits and label axes.</span>
<span class="n">ylim</span><span class="p">([</span><span class="o">-.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">])</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of spikes in the past&#39;</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Autocorrelation&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_116_0.png" src="_images/08_116_0.png" />
</div>
</div>
<p>Notice that we include confidence bounds determined by the size of the sequence of interest (in this case, the length of the ISIs).
We see that the autocorrelation function has just a few isolated lags that are outside of the significance bounds. This could indicate a weak relation at particular lags or could be due to chance. Assuming the latter suggests that the data may come from a renewal process, a spiking process with independent ISIs for which the probability of a spike at any time only depends on the time of the most recent spike. One advantage of working with renewal processes is that it is fairly easy to write down and fit statistical models to the data. That is our next step.</p>
<div class="question">
<p><strong>Q.</strong> Compute the correlation between ISIs for the data in the high-light condition. What do you find? Are these data consistent with a renewal process?</p>
</div><p><a class="reference external" href="#top">Back to top</a>
<a id="models"></a></p>
</div>
</div>
<div class="section" id="building-statistical-models-of-the-isis">
<h2>Building Statistical Models of the ISIs<a class="headerlink" href="#building-statistical-models-of-the-isis" title="Permalink to this headline">¶</a></h2>
<p>In the previous sections, we constructed autocorrelation functions of the increment processes and autocorrelation functions of the sequences of ISIs. The former suggested dependence going back up to <span class="math notranslate nohighlight">\(\approx\)</span> 50 ms (<a href="#fig:8-12" class="fig">figure<span><img src="imgs/8-12.png"></span></a>), while the latter suggested that the spiking at any time depends only on the timing of the most recent spike (<a href="#fig:8-14" class="fig">figure<span><img src="imgs/8-14.png"></span></a>). We now consider another powerful technique to understand these data: building a model. More specifically, we construct a <em>statistical model</em> of these data. This model captures important features of the data but does not consist of explicit biophysical components (an example of a biologically explicit model is the Hodgkin-Huxley equations <a href="https://doi.org/10.1113/jphysiol.1952.sp004764" rel="external">[Hodgkin &amp; Huxley, 1952]</a>). The notion of a model can be confusing and is audience dependent, so we clarify here.</p>
<p>To construct a statistical model for these data we assume that the ISIs are independent samples from some unknown distribution. We typically posit some class of distributions from which the data might arise, and identify the one distribution in that class that maximizes the chance of observing the actual data.</p>
<p>What class of distributions should we use to build an ISI model? Previously, we discussed a Poisson process as a basic model for a spiking process, consistent with the conceptual idea of spikes as coin flips. Let’s fit a Poisson process with a constant firing rate to the observed data. In other words, we begin with a model where the number of spikes in any time bin is independent of all previous (and future) spiking and has a Poisson distribution with a fixed but unknown rate parameter <span class="math notranslate nohighlight">\(\lambda\)</span>. The probability <span class="math notranslate nohighlight">\(P\)</span> of <span class="math notranslate nohighlight">\(k\)</span> spikes in any time bin is given by the Poisson distribution,
<a id="eq:6"></a></p>
<div class="math notranslate nohighlight">
\[
  P(k) = \frac{
  \lambda^k e^{-\lambda}
  }{
  k!
  },
  \tag{6}
\]</div>
<p>where <span class="math notranslate nohighlight">\(k!\)</span> is the factorial of <span class="math notranslate nohighlight">\(k\)</span>. Under this model, the distribution for the number of spikes in a bin is Poisson, but what is the distribution of the waiting time between spikes (i.e., what is the distribution of the ISIs)? It can be shown that for any Poisson process with constant firing rate the ISIs have an exponential distribution <a href="http://dx.doi.org/10.1007/978-1-4614-9602-1" rel="external">[Kass, Eden &amp; Brown, 2014]</a>. Mathematically, the probability density function for any ISI taking on a value <span class="math notranslate nohighlight">\(x\)</span> is
<a id="eq:7"></a></p>
<div class="math notranslate nohighlight">
\[
  f(x) = \lambda \exp(-\lambda x),
  \tag{7}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda\)</span> is the rate parameter for the Poisson process.</p>
<div class="math-note">
<p><strong>Alert!</strong> This is a common point of confusion. The increments of a Poisson process have a Poisson distribution, and the ISIs have an exponential distribution. The Poisson distribution takes on non-negative integer values {0,1,…,<span class="math notranslate nohighlight">\(\infty\)</span>}, which make it appropriate for counting the number of spikes in an interval. The Poisson distribution does not make sense to describe the waiting time between spikes, since this typically takes on a continuous value in [0, <span class="math notranslate nohighlight">\(\infty\)</span>].</p>
</div><p>Our goal is to find a good value of <span class="math notranslate nohighlight">\(\lambda\)</span> so that our statistical model (<a href="#eq:7" class="thumb">7<span><img src="imgs/eq7.png"></span></a>) matches the observed ISI distributions. Let’s guess some values for <span class="math notranslate nohighlight">\(\lambda\)</span>, evaluate the model (<a href="#eq:7" class="thumb">7<span><img src="imgs/eq7.png"></span></a>), and see how well the model matches the data. Let’s plot the probability of observing ISI values in 1 ms bins for the low-light condition. This is similar to the ISI histogram we plotted previously except that the <span class="math notranslate nohighlight">\(y\)</span>-axis should represent probability instead of counts. To do so, we simply divide each count value by the total number of ISIs in the low-light condition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>           <span class="c1"># Define 1 ms bins for histogram,</span>
<span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>  <span class="c1"># ... compute histogram of the ISIs,</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>             <span class="c1"># ... convert to probability,</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">()</span>                 <span class="c1"># ... create figure and axes objects that we can reuse later,</span>
<span class="n">ax</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">prob</span><span class="p">)</span>                 <span class="c1"># ... and plot the probabilities,</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">])</span>                   <span class="c1"># ... with fixed x-limits,</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;ISI [s]&#39;</span><span class="p">)</span>                        <span class="c1"># ... and axes labeled.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="stderr docutils container">
<pre class="stderr literal-block">/anaconda3/envs/csn/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.
  &quot;&quot;&quot;
</pre>
</div>
<img alt="_images/08_122_1.png" src="_images/08_122_1.png" />
</div>
</div>
<p>Now, on the same figure, let’s choose a value for <span class="math notranslate nohighlight">\(\lambda\)</span> and plot the statistical model (<a href="#eq:7" class="thumb">7<span><img src="imgs/eq7.png"></span></a>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">l</span> <span class="o">=</span> <span class="mi">5</span>                                    <span class="c1"># Choose a value for lambda,</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">l</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">l</span> <span class="o">*</span> <span class="n">bins</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span>    <span class="c1"># ... and create the model,</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">)</span>                <span class="c1"># ... and plot the model in green</span>
<span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_124_0.png" src="_images/08_124_0.png" />
</div>
</div>
<p>In this code, we have chosen <span class="math notranslate nohighlight">\(\lambda\)</span> = 5 Hz and evaluated the statistical model at each time bin. We’ve also scaled the statistical model by a factor of 0.001 to match the 1 ms bin size, and plotted the model on top of the empirical ISI probability distribution.</p>
<div class="question">
<p><strong>Q.</strong> Try using some different values of <span class="math notranslate nohighlight">\(\lambda\)</span>. What values of <span class="math notranslate nohighlight">\(\lambda\)</span> appear to provide a good fit to the empirical distribution of ISI values?</p>
</div><p>The process of guessing values of <span class="math notranslate nohighlight">\(\lambda\)</span> and comparing the model (<a href="#eq:7" class="thumb">7<span><img src="imgs/eq7.png"></span></a>) to the empirical ISI distribution is not satisfying. How do we identify the parameter <span class="math notranslate nohighlight">\(\lambda\)</span> that best fits the observed ISI distribution? We now consider a procedure to do so. Our goal is to find the value of <span class="math notranslate nohighlight">\(\lambda\)</span> that maximizes the likelihood of the data given the statistical model (<a href="#eq:7" class="thumb">7<span><img src="imgs/eq7.png"></span></a>); this value of <span class="math notranslate nohighlight">\(\lambda\)</span> will be the best fit of the model to the data. To implement this procedure, let’s consider the probability density of observing a sequence of ISIs, <span class="math notranslate nohighlight">\(x_1, x_2, ..., x_n\)</span>. If we assume that the ISIs are independent, then the probability density is
<a id="eq:8"></a></p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{eqnarray}
  f(x_1, x_2, ..., x_n) &amp;=&amp; f(x_1) f(x_2) ... f(x_n) \\ 
  &amp;=&amp; \lambda \exp(-\lambda x_1) \lambda \exp(-\lambda x_2) ... \lambda \exp(-\lambda x_n) \\
  &amp;=&amp; \lambda ^n \exp(-\lambda \sum_{i=1}^n x_i). \\   \tag{8}
  \end{eqnarray}
\end{split}\]</div>
<p>We call this expression the joint probability distribution of the observed data. In the first equality, we separate the joint probability distribution <span class="math notranslate nohighlight">\(f(x_1,x_2,...,x_n)\)</span> into a product of probability distributions of each event (i.e., <span class="math notranslate nohighlight">\(f(x_1)\)</span>, the probability of the first ISI equaling <span class="math notranslate nohighlight">\(x_1\)</span>; multiplied by <span class="math notranslate nohighlight">\(f(x_2)\)</span>, the probability of the second ISI equaling <span class="math notranslate nohighlight">\(x_2\)</span>; multiplied by <span class="math notranslate nohighlight">\(f(x_3)\)</span>, the probability of the third ISI equaling <span class="math notranslate nohighlight">\(x_3\)</span>; and so on). This partitioning of the joint probability is valid here because we assume the ISIs are independent. In the second equality, we replace each probability distribution with the exponential distribution we expect for the ISIs of a Poisson process. In the last equality, we rewrite the expression as a single exponential. Notice that this last expression is a function of the unknown rate parameter, <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
<p>When considered as a function of the unknown parameters, the joint distribution of the data (<a href="#eq:8" class="thumb">8<span><img src="imgs/eq8.png"></span></a>) is also called the <em>likelihood</em>. In this case, we write
<a id="eq:9"></a></p>
<div class="math notranslate nohighlight">
\[
  L(\lambda) = \lambda^n e^{-\lambda (x_1 + x_2 + ... + x_n)},
  \tag{9}
\]</div>
<p>to indicate that the likelihood <span class="math notranslate nohighlight">\(L\)</span> is a function of <span class="math notranslate nohighlight">\(\lambda\)</span>. To understand what the likelihood function <span class="math notranslate nohighlight">\(L(\lambda)\)</span> looks like, let’s plot it. We do so for the data from the low-light condition, and consider a range of possible <span class="math notranslate nohighlight">\(\lambda\)</span> values.
<a id="fig:8-16"></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lambdas</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>  <span class="c1"># Range of lambda values.</span>
<span class="n">N3</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>        <span class="c1"># Number of low-light ISIs observed.</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">lambdas</span> <span class="o">**</span> <span class="n">N3</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lambdas</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">))</span>  <span class="c1"># Compute the likelihood,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>         <span class="c1"># ... and plot it.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$\lambda$&#39;</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Likelihood&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_128_0.png" src="_images/08_128_0.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> Consider the plot above. Does this answer seem okay?</p>
<p><strong>A.</strong> Something went wrong here. The plot gives part of a line that rises toward <span class="math notranslate nohighlight">\(10^{-13}\)</span> and is zero elsewhere. Why does this happen, and how can we fix it? To answer this, consider the first term in the likelihood function, <span class="math notranslate nohighlight">\(\lambda ^n\)</span>. In this case we are raising <span class="math notranslate nohighlight">\(\lambda\)</span> to the power of <code class="docutils literal notranslate"><span class="pre">len(ISIsLow)</span></code> = 749. This is beyond the numerical precision limits of standard Python computations.</p>
</div><p>So, we can’t easily plot the likelihood directly. Instead, we plot the log of the likelihood. In this case, computing the log is useful because extremely large values are reduced to a more manageable range.
<a id="fig:8-17"></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lambdas</span> <span class="o">=</span> <span class="n">lambdas</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># Update the lambda range to exclude 0.</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">N3</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">lambdas</span><span class="p">)</span> <span class="o">-</span> <span class="n">lambdas</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>  <span class="c1"># Compute the log likelihood,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">lambdas</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>       <span class="c1"># ... and plot it.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$\lambda$&#39;</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Log likelihood&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_131_0.png" src="_images/08_131_0.png" />
</div>
</div>
<div class="question">
<p><strong>Q.</strong> Consider the second line of code above. Does the definition for <code class="docutils literal notranslate"><span class="pre">l</span></code> correspond to <span class="math notranslate nohighlight">\(\log[L(\lambda)]\)</span> where the likelihood <span class="math notranslate nohighlight">\(L(\lambda)\)</span> is defined in (<a href="#eq:9" class="thumb">eq.<span><img src="imgs/eq9.png"></span></a>)? <em>Hint</em>: It should. Remember <span class="math notranslate nohighlight">\(\log(x^a)=a \, \log x\)</span>, and <span class="math notranslate nohighlight">\(\log(e^b)=b\)</span>.</p>
</div><p>We see that the log likelihood is low for small <span class="math notranslate nohighlight">\(\lambda\)</span>, rises quickly as <span class="math notranslate nohighlight">\(\lambda\)</span> increases, and then starts to fall off once <span class="math notranslate nohighlight">\(\lambda\)</span> becomes larger than <span class="math notranslate nohighlight">\(\approx\)</span> 25. The point <span class="math notranslate nohighlight">\(\lambda\)</span> = 25, where the log likelihood is maximized, is called the <strong>maximum likelihood estimate</strong> of <span class="math notranslate nohighlight">\(\lambda\)</span>. We use the symbol <span class="math notranslate nohighlight">\(\hat\lambda\)</span> to denote the maximum likelihood estimate of <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
<p>We observe that although the values of the likelihood go beyond the precision range in Python, the peak in the log likelihood stands out very clearly. Note that the likelihood (<a href="#fig:8-16" class="fig">figure<span><img src="imgs/8-16.png"></span></a>) is maximized at the same point as the log likelihood (<a href="#fig:8-17" class="fig">figure<span><img src="imgs/8-17.png"></span></a>). This is always true.</p>
<div class="question">
<p><strong>Q.</strong> Can you explain why?</p>
</div><p>We could also have computed the maximum likelihood estimator theoretically, by differentiating the log likelihood with respect to <span class="math notranslate nohighlight">\(\lambda\)</span>, setting that equal to zero, and solving for <span class="math notranslate nohighlight">\(\lambda\)</span>. This gives <span class="math notranslate nohighlight">\(\frac{n}{\hat\lambda} - \sum_{i=1}^n x_i = 0\)</span>, which can be solved to find <span class="math notranslate nohighlight">\(\hat\lambda=n(\sum_{i=1}^n x_i)^{-1} = 1 / \bar{x} = 25.0\)</span> spikes/s. Remember that <span class="math notranslate nohighlight">\(x_i\)</span> is the <span class="math notranslate nohighlight">\(i^{th}\)</span> ISI value, so <span class="math notranslate nohighlight">\(\bar x\)</span> is the average ISI value. This computation shows that the maximum likelihood estimate for the rate parameter of a Poisson process is just 1 divided by the average ISI value. For some statistical models, it is convenient to compute maximum likelihood estimates theoretically in this manner, but sometimes no closed-form solution exists. In these cases, we typically use numerical methods to solve for the maximum likelihood estimates.</p>
<div class=question>
<p><strong>Q.</strong> What is the maximum likelihood estimate for the Poisson rate parameter in the high-light condition?</p>
<p><strong>A.</strong> Repeating the analysis for the high-light condition, the maximum likelihood estimate for a Poisson rate parameter is <span class="math notranslate nohighlight">\(\hat \lambda = n(\sum{i=1}^nx_i)^{-1} = 1 / \bar x = 32.3\)</span> spikes/s. The difference in the Poisson rate parameter of 32.3 - 25.0 = 7.3 spikes/s reflects the difference in the overall firing rate of the neuron between the low-and high-light conditions.</p>
</div><div class=question>
<p><strong>Q.</strong> Is the difference in the Poisson rate parameter between the low-and high-light conditions statistically significant?</p>
</div><p>To address this last question, let’s use a bootstrap analysis (see an introduction to the bootstrap in
<a href="02" rel="local">this notebook</a>). We combine all the ISIs from both conditions into one pool, sample many new datasets with replacement from that pool, and compare the actual difference in rate parameters to the distribution of differences across the samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute the observed difference in lambdas.</span>
<span class="n">MLDiff</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">ISIsHigh</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">ISIsLow</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Then, perform the bootstrap analysis.</span>
<span class="n">ISIs</span> <span class="o">=</span> <span class="n">hstack</span><span class="p">([</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="n">ISIsHigh</span><span class="p">])</span>     <span class="c1"># Merge all ISIs.</span>
<span class="n">Nall</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIs</span><span class="p">)</span>                       <span class="c1"># Save length of all ISIs.</span>
<span class="n">Nlo</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>                     <span class="c1"># Save length for the low-light condition.</span>
<span class="n">Nhi</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsHigh</span><span class="p">)</span>                    <span class="c1"># Save length high-light condition.</span>

<span class="c1"># Compute the difference in lambdas from resampled data</span>
<span class="n">sampDiff</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="o">/</span> <span class="n">mean</span><span class="p">(</span><span class="n">ISIs</span><span class="p">[</span><span class="n">randint</span><span class="p">(</span><span class="n">Nall</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Nhi</span><span class="p">)])</span> <span class="o">-</span>  <span class="c1"># Resample the high-light ISIs and subtract</span>
            <span class="mi">1</span> <span class="o">/</span> <span class="n">mean</span><span class="p">(</span><span class="n">ISIs</span><span class="p">[</span><span class="n">randint</span><span class="p">(</span><span class="n">Nall</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Nlo</span><span class="p">)])</span>    <span class="c1"># ... the resampled low-light ISIs</span>
           <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)]</span>                                    <span class="c1"># ... 1000 times.</span>

<span class="c1"># Compare the bootstrap distribution to the empirical</span>
<span class="n">hist</span><span class="p">(</span><span class="n">sampDiff</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>            <span class="c1"># Plot resampled ISIs distribution,</span>
<span class="n">plot</span><span class="p">([</span><span class="n">MLDiff</span><span class="p">,</span> <span class="n">MLDiff</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>       <span class="c1"># ... and the empirical ISIs.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Counts&#39;</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Difference in rate (spikes/s)&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_139_0.png" src="_images/08_139_0.png" />
</div>
</div>
<div class=math-note>
<p>There are more powerful tests we could use to compare the Poisson rate parameters. By more powerful, we mean that the tests are more likely to show a significant difference when one is actually present. However, here we find that the bootstrap test gives a significant result; notice that the observed difference in rate parameters (blue) lines lies well outside the bootstrap distribution of values (red). We conclude that a more powerful test would also be significant.</p>
</div><p>We’ve now fit a Possion model to the data. But, does the Poisson model provide a good fit to the data? To answer this, let’s visualize the model fits compared to the data. There are a number of ways to do this. We start by comparing the expected proportion of ISIs for a Poisson process to the ISI histograms we actually observe in each condition. Let’s do so first for the low-light condition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>            <span class="c1"># Define 1 ms bins for histogram.</span>
<span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>   <span class="c1"># Compute histogram,</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>              <span class="c1"># ... convert to probability,</span>
<span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">prob</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>     <span class="c1"># ... and plot probability.</span>
<span class="n">lbda</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">ISIsLow</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>                 <span class="c1"># Compute best guess for lambda,</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lbda</span> <span class="o">*</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lbda</span> <span class="o">*</span> <span class="n">bins</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span>  <span class="c1"># ... build the model,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>                    <span class="c1"># ... and plot it.</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">])</span>                       <span class="c1"># ... xlim from 0 to 150 ms,</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;ISI [s]&#39;</span><span class="p">)</span>                         <span class="c1"># ... label the x-axis,</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>                     <span class="c1"># ... and the y-axis.</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_142_0.png" src="_images/08_142_0.png" />
</div>
</div>
<div class=question>
<p><strong>Q.</strong> Compare the model fit to the empirical ISI distribution for the low-light condition. Does the model fit the data?</p>
<p><strong>A.</strong> No, the model does not provide a very good fit to the data. Since Poisson processes have spikes that are independent of past activity, they do not capture either the refractoriness (i.e., the few spikes observed at short times) or the bursting (i.e., the increased spiking at times 5–20 ms) that we observe in the data.</p>
</div><div class=question>
<p><strong>Q.</strong> Repeat the analysis and compare the empirical ISI histogram to the best-fit model in the high-light condition. Does the model fit the data?</p>
</div><p>To go beyond visual inspection of the model fits and quantify the goodness of fit, we compare the cumulative distributions computed from the data and model. The <strong>cumulative distribution function</strong> (CDF), <span class="math notranslate nohighlight">\(F(x)\)</span>, is the probability that a random variable will take on a value less than or equal to <span class="math notranslate nohighlight">\(x\)</span>. For the exponential ISI model with rate parameter <span class="math notranslate nohighlight">\(\lambda\)</span>, the model CDF is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{eqnarray}
  F_{mod}(x) &amp;=&amp; \Pr(\mbox{ISI} \leq x) \\
  &amp;=&amp; \int_0^x \lambda e^{-\lambda t} dt \\
  &amp;=&amp; 1 - e^{-\lambda x}.
  \end{eqnarray}
\end{split}\]</div>
<p>We compare this to the empirical CDF of the data, <span class="math notranslate nohighlight">\(F_{emp}(x)\)</span>, which is defined as the proportion of observations less than or equal to <span class="math notranslate nohighlight">\(x\)</span>. The code to compute and plot these CDFs for the low light-condition is as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>     <span class="c1"># Define 1 ms bins for histogram,</span>
<span class="n">lbda</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">ISIsLow</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>           <span class="c1"># Compute best guess for lambda,</span>
<span class="n">FmodLow</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lbda</span> <span class="o">*</span> <span class="n">bins</span><span class="p">)</span>  <span class="c1"># ... and define model CDF.</span>
<span class="n">FempLow</span> <span class="o">=</span> <span class="n">cumsum</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>           <span class="c1"># Define empirical CDF.</span>
<span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">FmodLow</span><span class="p">,</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>                 <span class="c1"># Plot the model CDF,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">FempLow</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>       <span class="c1"># ... and the empirical CDF,</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>                  <span class="c1"># ... with specified x-limits.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time [s]&#39;</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;CDF&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_147_0.png" src="_images/08_147_0.png" />
</div>
</div>
<div class=question>
<p><strong>Q.</strong> Have you used the function <code class="docutils literal notranslate"><span class="pre">cumsum()</span></code> before? If not, look it up using <code class="docutils literal notranslate"><span class="pre">cumsum?</span></code></p>
</div><div class=question>
<p><strong>Q.</strong> Compare the model and empirical CDFs in the plot above. What do you think?</p>
<p><strong>A.</strong> If the model were a perfect fit, the two curves would align. However, that’s not what we find here. We conclude that the model may not provide a good fit to the data.</p>
</div><div class=question>
<p><strong>Q.</strong> Compare the model and empirical CDF for the data in the high-light condition. What do you find? Is the model a good fit to the data?</p>
</div><p>Another common way to visualize the difference between the model and empirical distributions is a <em>Kolmogorov-Smirnov</em> (KS) plot. This is just a plot of the empirical CDF against the model CDF directly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">()</span>
<span class="n">plot</span><span class="p">(</span><span class="n">FmodLow</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">FempLow</span><span class="p">)</span>    <span class="c1"># Plot the model vs empirical CDFs.</span>
<span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>         <span class="c1"># Set the axes ranges.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Model CDF&#39;</span><span class="p">)</span>            <span class="c1"># And label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Empirical CDF&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_152_0.png" src="_images/08_152_0.png" />
</div>
</div>
<p>Since the KS plot compares CDFs, both the <span class="math notranslate nohighlight">\(x\)</span>-axis and <span class="math notranslate nohighlight">\(y\)</span>-axis range from 0 to 1. A perfect fit between the model and empirical CDFs would look like a straight, 45-degree line between the points (0,0) and (1,1). Any deviation from this line represents deviation between the observed and model distributions. One nice result for comparing CDFs is that with enough data, the maximum difference between the model and empirical CDFs has a known asymptotic distribution, which can be used to put confidence bounds about the KS plot <a href="http://dx.doi.org/10.1007/978-1-4614-9602-1" rel="external">[Kass, Eden &amp; Brown, 2014]</a>. For 95% confidence bounds, a well-fit model should stay within ±1.36/<span class="math notranslate nohighlight">\(\sqrt N\)</span> of the 45-degree line, where <span class="math notranslate nohighlight">\(N\)</span> is the number of ISIs observed. Let’s place these confidence bounds on the KS plot:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Nlow</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>  <span class="c1"># Length of the low-light condition</span>
<span class="c1"># Plot the confidence bounds</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="mf">1.36</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">Nlow</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="s1">&#39;k:&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span> <span class="o">-</span> <span class="mf">1.36</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">Nlow</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="s1">&#39;k:&#39;</span><span class="p">)</span>
<span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_154_0.png" src="_images/08_154_0.png" />
</div>
</div>
<p>A well-fit model should stay entirely within these bounds. In this case, the KS plot for the low-light condition extends well outside these bounds. The exponential ISI model—or equivalently, the Poisson process model—does not fit the data in the low-light condition well. This suggests that we need a better model if we want to make meaningful comparisons about differences in the structure of the data between the two conditions.</p>
<div class=question>
<p><strong>Q.</strong> Compute the KS plto with 95% significance bounds or the high-light condition. Does the exponential ISI model fit the data well?</p>
</div><div class="section" id="a-more-advanced-statistical-model">
<h3>A More Advanced Statistical Model.<a class="headerlink" href="#a-more-advanced-statistical-model" title="Permalink to this headline">¶</a></h3>
<p>We’ve now investigated one class of models, the exponential distribution, to fit the observed ISI distributions. However, through analysis, we’ve found that this statistical model is not sufficient to mimic the observed data. There are many other choices for statistical models; let’s try one other class of models. The inverse Gaussian probability model has already been used successfully to describe ISI structure in this system <a href="https://www.ncbi.nlm.nih.gov/pubmed/9394447" rel="external">[Iyengar &amp; Liao, 1997]</a>). The mathematical expression for the inverse Gaussian probability density is,</p>
<div class="math notranslate nohighlight">
\[
  f(x) = \sqrt{\frac{\lambda}{2 \pi x^3}}\exp\left(\frac{-\lambda(x - \mu)^2}{2 x \mu^2}\right) \, .
  \tag{10}
\]</div>
<p>The inverse Gaussian distribution has two parameters that determine its shape: <span class="math notranslate nohighlight">\(\mu\)</span>, which determines the mean of the distribution; and <span class="math notranslate nohighlight">\(\lambda\)</span>, which is called the shape parameter. At <span class="math notranslate nohighlight">\(x\)</span> = 0, the inverse Gaussian has a probability density equal to zero, which suggests it could capture some of the refractoriness seen in the data.</p>
<p>If we again assume that the ISIs are independent of each other, then the likelihood of observing the sequence of ISIs, <span class="math notranslate nohighlight">\(x_1 , x_2 , . . . , x_n\)</span>, is the product of the probabilities of each ISI,</p>
<div class="math notranslate nohighlight">
\[
  L(\mu, \lambda) = f(x_1, x_2, ..., x_n) = \prod_{i=1}^N\sqrt{\frac{\lambda}{2\pi x_i^3}}\exp\left(\frac{-\lambda(x_i - \mu)^2}{2 x_i \mu^2}\right)
  \tag{11}
\]</div>
<p>The log likelihood is then</p>
<div class="math notranslate nohighlight">
\[
  \log\big(L(\mu, \lambda)\big) = \frac{N}{2}\log\frac{\lambda}{2\pi} - \frac{3}{2}\sum_{i=1}^N \log{x_i} - \sum_{i=1}^N\frac{\lambda(x_i - \mu)^2}{2x_i \mu^2}.
  \tag{12}
\]</div>
<p>Since this distribution has two parameters, the maximum likelihood solution for this model is the pair of parameter estimates <span class="math notranslate nohighlight">\(\hat\mu\)</span>, <span class="math notranslate nohighlight">\(\hat\lambda\)</span> that maximizes the likelihood of the data. We can solve for the maximum likelihood estimate analytically by taking the derivative with respect to both parameters, setting these equal to zero, and solving the resulting set of equations. In this case, the maximum likelihood estimators are</p>
<div class="math notranslate nohighlight">
\[
  \hat\mu = \frac{1}{N}\sum_{i=1}^N x_i
  \tag{13}
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
  \hat\lambda = \left( \frac{1}{N}\sum_{i=1}^N\left(\frac{1}{x_i} - \frac{1}{\bar \mu}\right)\right)^{-1}.
  \tag{14}
\]</div>
<p>Using this expression, we can fit an inverse Gaussian model to the data in each condition and evaluate the goodness-of-fit of the model. Let’s do so now for the low-light condition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bins</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>    <span class="c1"># Define 1 ms bins.</span>
<span class="n">Nlow</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>               <span class="c1"># Length of low-light condition.</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">ISIsLow</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>               <span class="c1"># Mean of inverse Gaussian</span>
<span class="n">lbda</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">ISIsLow</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>    <span class="c1"># ... and shape parameter</span>
<span class="n">model</span> <span class="o">=</span> <span class="p">(</span>                                   <span class="c1"># ... to create the model.</span>
    <span class="n">sqrt</span><span class="p">(</span><span class="n">lbda</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">pi</span> <span class="o">/</span> <span class="n">bins</span> <span class="o">**</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> 
    <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">lbda</span> <span class="o">*</span> <span class="p">(</span><span class="n">bins</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span>       
           <span class="mi">2</span> <span class="o">/</span> <span class="n">mu</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">bins</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span>
<span class="p">)</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>                      <span class="c1"># Numerator to 0 faster than denominator.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;mu = &#39;</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>                <span class="c1"># Display the MLEs.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lambda = &#39;</span><span class="p">,</span> <span class="n">lbda</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>mu =  0.039988397284383186
lambda =  0.04931816769253932
</pre></div>
</div>
<div class="stderr docutils container">
<pre class="stderr literal-block">/anaconda3/envs/csn/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide
  
/anaconda3/envs/csn/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply
  
</pre>
</div>
</div>
</div>
<div class=python-note>
<p>Note that the first element of <code class="docutils literal notranslate"><span class="pre">bins</span></code> is 0, so dividing by <code class="docutils literal notranslate"><span class="pre">bins</span></code> causes a divide by zero warning.</p>
</div><p>From the computations, we find maximum likelihood estimates <span class="math notranslate nohighlight">\(\mu\)</span> = 40.0 ms and <span class="math notranslate nohighlight">\(\lambda\)</span> = 49.3 ms in the low-light condition. Next, we plot the data and the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the data and the model,</span>
<span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">histogram</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>  <span class="c1"># Compute histogram,</span>
<span class="n">prob</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ISIsLow</span><span class="p">)</span>             <span class="c1"># ... convert to probability,</span>
<span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">prob</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>     <span class="c1"># ... and plot probability.</span>
<span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>                   <span class="c1"># Plot the model.</span>
<span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>                       <span class="c1"># xlim from 0 to 200 ms.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;ISI [s]&#39;</span><span class="p">)</span>                        <span class="c1"># Label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>

<span class="c1"># Plot the KS plot</span>
<span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">FmodLow</span> <span class="o">=</span> <span class="n">cumsum</span><span class="p">(</span><span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>          <span class="c1"># Define the model CDF,</span>
<span class="n">FempLow</span> <span class="o">=</span> <span class="n">cumsum</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span>                <span class="c1"># ... and define empirical CDF,</span>
<span class="n">plot</span><span class="p">(</span><span class="n">FmodLow</span><span class="p">,</span> <span class="n">FempLow</span><span class="p">)</span>                   <span class="c1"># ... plot model vs empirical CDF,</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.36</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">Nlow</span><span class="p">),</span><span class="s1">&#39;k:&#39;</span><span class="p">)</span>  <span class="c1"># ... upper confidence bound,</span>
<span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.36</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">Nlow</span><span class="p">),</span><span class="s1">&#39;k:&#39;</span><span class="p">)</span>  <span class="c1"># ... lower confidence bound,</span>
<span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>                   <span class="c1"># ... set the axes ranges,</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Model CDF&#39;</span><span class="p">)</span>                      <span class="c1"># ... and label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Empirical CDF&#39;</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/08_161_0.png" src="_images/08_161_0.png" />
</div>
</div>
<div class=question>
<p><strong>Q.</strong> Consider the fit of the inverse Gaussian model to the data in the low-light condition. Does the inverse Gaussian model provide a good fit to the ISIs?</p>
<p><strong>A.</strong> This model provides a much better fit to the data; the KS plot is contained within the 95% confidence bounds.</p>
</div><div class=question>
<p><strong>Q.</strong> Consider the fit of the inverse Gaussian model to the data in the high-light condition. Does the inverse Gaussian model provide a good fit to these ISIs?</p>
</div><div class=question>
<p><strong>Q.</strong> Compare the estimates of the two parameters <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\lambda\)</span> of the inverse Gaussian model in the two conditions. What do these reveal about the differences between the low- and high-light conditions?</p>
</div><p><a class="reference external" href="#top">Back to top</a>
<a id="summary"></a></p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this notebook, we considered the spiking activity recorded in two conditions. We began with visualizations of the spiking data, and construction and visualization of the increment process (i.e., binned spike counts). We then assessed the variability in the increments through computation of the Fano factor, and showed that the low- and high-light conditions had less and more variability, respectively, than expected for a Poisson process. We also assessed the autocorrelation of the increment processes and observed the impact of refractoriness and bursting activity. In addition, we created and visualized the ISIs for each condition. Inspection of the ISI histograms suggested bursting activity in both conditions, and more small ISIs in the high-light condition. Analysis of the ISI autocorrelations revealed no compelling evidence for dependence and supported the hypothesis of a renewal process. Finally, we built two statistical models of the observed ISIs. We discussed how to fit the model parameters by computing the maximum likelihood estimate, and how to evaluate the model goodness-of-fit to the data using the KS plot. We showed that the first model—the Poisson process as a model of spiking with a corresponding exponential distribution of ISIs—did not fit the observed ISI data. A second model—the inverse Gaussian probability model—provided a much more accurate fit to the observed ISIs. The modeling suggests that at least two features of the spiking activity have changed from the low-light to the high-light condition. First, the mean ISI is smaller, and hence the average firing rate is larger, in the high-light condition. Second, the shape of the firing distribution has changed so that the cell is more likely to fire in bursts with short ISIs in the high-light condition.</p>
<p><a class="reference external" href="#top">Back to Top</a>
<a id="appendix"></a></p>
</div>
<div class="section" id="appendix-spike-count-mean-and-variance-for-a-poisson-process">
<h2>Appendix: Spike Count Mean and Variance for a Poisson Process<a class="headerlink" href="#appendix-spike-count-mean-and-variance-for-a-poisson-process" title="Permalink to this headline">¶</a></h2>
<p>In this appendix, we compute the theoretical mean <span class="math notranslate nohighlight">\(\mu\)</span> and the theoretical variance of the spike count <span class="math notranslate nohighlight">\(\sigma^2\)</span> for a Poisson process. Let’s compute <span class="math notranslate nohighlight">\(\mu\)</span> using a general formula that makes use of the probability <span class="math notranslate nohighlight">\(P(k)\)</span> of observing <span class="math notranslate nohighlight">\(k\)</span> spikes,
<a id="eq:15"></a></p>
<div class="math notranslate nohighlight">
\[
  \mu = \sum_{k=1}^\infty k P(k).
\]</div>
<p>Replacing <span class="math notranslate nohighlight">\(P(k)\)</span> with the expression for a Poisson distribution
(<a href="#eq:6" class="thumb">eq.<span><img src="imgs/eq6.png"></span></a>)
, we find</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{eqnarray}
  \mu &amp;=&amp; \sum_{k=0}^\infty k\left(\frac{\lambda^k e^{-k}}{k!}\right) \\
  &amp;=&amp; e^{-\lambda}\sum_{k=0}^\infty k\frac{\lambda^k}{k!}.
  \end{eqnarray}
\end{split}\]</div>
<p>To make progress, let’s write out the terms in the summation,
<a id="eq:16"></a></p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{eqnarray}
  \mu &amp;=&amp; e^{-\lambda}
  \left( 
  0 + 
  \frac{\lambda^1}{1!} + 
  2\frac{\lambda^2}{2!} + 
  3\frac{\lambda^3}{3!} + 
  4\frac{\lambda^4}{4!} + 
  \cdots 
  \right) \\
  &amp;=&amp; e^{-\lambda}\lambda
  \left(
  1 + 
  \frac{\lambda^2}{2!} + 
  \frac{\lambda^3}{3!} + 
  \cdots 
  \right) \\
  &amp;=&amp; e^{-\lambda}\lambda(e^\lambda) \\
  &amp;=&amp; \lambda,
  \end{eqnarray}
\end{split}\]</div>
<p>where we have used the fact that <span class="math notranslate nohighlight">\(e^x = 1 + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \cdots\)</span>. Notice that the mean spike count equals the rate parameter of the Poisson process.</p>
<p>To find the spike count variance for a Poisson process, we follow a similar procedure. In general, we compute the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> of the spike count <span class="math notranslate nohighlight">\(k\)</span> with probability distribution <span class="math notranslate nohighlight">\(P(k)\)</span> as
<a id="eq:17"></a></p>
<div class="math notranslate nohighlight">
\[
  \sigma^2 = \sum_{k=0}^\infty k^2 P(k) - \left(\sum_{k=0}^\infty k P(k)\right) ^2.
\]</div>
<p>As in our computation of the mean spike count, we replace <span class="math notranslate nohighlight">\(P(k)\)</span> with (<a href=#eq:6 class=thumb>eq.<span><img src=imgs/eq6.png></span></a>)
, the expression for a Poisson process. Notice that the second term is the square of the expression (<a href=#eq:15 class=thumb>eq.<span><img src=imgs/eq15.png></span></a>)
, and for a Poisson process we found <span class="math notranslate nohighlight">\(\mu = \lambda\)</span>. Therefore, let’s replace the second term in (<a href=#eq:17 class=thumb>eq.<span><img src=imgs/eq17.png></span></a>)
with <span class="math notranslate nohighlight">\(\sigma^2\)</span> and substitute for <span class="math notranslate nohighlight">\(P(k)\)</span> in the first term of (<a href=#eq:17 class=thumb>eq.<span><img src=imgs/eq17.png></span></a>) to find</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{eqnarray}
  \sigma^2 &amp;=&amp;
  \sum_{k=0}^\infty
  k^2
  \left(
  \frac{\lambda^k e^{-\lambda}}{k!}
  \right)
  - \lambda^2
  \\
  &amp;=&amp;
  e^{-\lambda}
  \sum_{k=0}^\infty
  k^2
  \frac{\lambda^k}{k!} 
  - \lambda^2.
  \end{eqnarray}
\end{split}\]</div>
<p>To make progress, we follow the same strategy and write out the terms in the summation,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{eqnarray}
  \sigma^2
  &amp;=&amp;
  e^{-\lambda}
  \left(
  0 + 
  \lambda +
  2^2\frac{\lambda^2}{2!} + 
  3^2\frac{\lambda^3}{3!} + 
  4^2\frac{\lambda^4}{4!} + 
  \cdots
  \right) - 
  \lambda^2
  \\
  &amp;=&amp;
  \lambda e ^{-\lambda}
  \left(
  1 + 
  2\lambda + 
  \frac{3}{2}\lambda ^2 + 
  \frac{4}{6}\lambda ^2 + 
  \cdots
  \right) - 
  \lambda^2.
  \end{eqnarray}
\end{split}\]</div>
<p>Now, we divide this sum of terms into two pieces, a “nice term” (in the first brackets) and “leftovers” (in the second brackets):</p>
<div class="math notranslate nohighlight">
\[
  \sigma^2 = \lambda e^{-\lambda}
  \left(
  \left[
  1 + 
  \lambda + 
  \frac{\lambda^2}{2!} + 
  \frac{\lambda^3}{3!} + 
  \cdots
  \right] + 
  \left[
  \lambda + 
  \frac{2\lambda^2}{2!} + 
  \frac{3\lambda^3}{3!} + 
  \cdots
  \right] 
  \right) - 
  \lambda^2.
\]</div>
<p>We can simplify by recognizing that,</p>
<div class="math notranslate nohighlight">
\[
  \left[
  1 + 
  \lambda + 
  \frac{\lambda^2}{2!} + 
  \frac{\lambda^3}{3!} + 
  \cdots
  \right]
  =
  e^\lambda \, .
\]</div>
<p>Then</p>
<p><a id="eq:18"></a>
<span class="math notranslate nohighlight">\($
  \begin{eqnarray}
  \sigma^2
  &amp;=&amp;
  \lambda e^{-\lambda}
  \left(
  e^\lambda + 
  \lambda
  \left[
  1 + 
  \frac{\lambda^1}{1!} + 
  \frac{\lambda^2}{2!} + 
  \cdots
  \right] 
  \right)-
  \lambda^2 \\
  &amp;=&amp;
  \lambda e^{-\lambda}
  \left(
  e^\lambda + \lambda e^\lambda
  \right)
  -\lambda^2 \\
  &amp;=&amp;
  \lambda + \lambda^2 - \lambda^2 \\
  &amp;=&amp;
  \lambda,
  \end{eqnarray}
$\)</span></p>
<p>where again we’ve used the definition of <span class="math notranslate nohighlight">\(e^\lambda\)</span>. We conclude that the spike count variance for a Poisson precess equals the firing rate <span class="math notranslate nohighlight">\(\lambda\)</span>.</p>
<p>Combining these results for the mean spike count <span class="math notranslate nohighlight">\(\mu\)</span>
(<a href=#eq:16 class=thumb>eq.<span><img src=imgs/eq16.png></span></a>)
and the spike count variance
(<a href=#eq:18 class=thumb>eq.<span><img src=imgs/eq18.png></span></a>),
we conclude that for a Poisson process,</p>
<div class="math notranslate nohighlight">
\[\mu = \sigma^2 = \lambda,\]</div>
<p>and therefore for a Poisson process, the Fano factor <span class="math notranslate nohighlight">\(\sigma^2/\mu=1\)</span>.</p>
<p><a class="reference external" href="#top">Back to top</a></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "Mark-Kramer/Case-Studies-Python",
            ref: "binder",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "."
        }
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="07.html" title="previous page">Cross-Frequency Coupling</a>
    <a class='right-next' id="next-link" href="09.html" title="next page">Point Process Generalized Linear Models</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Mark Kramer and Uri Eden<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-175303310-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>