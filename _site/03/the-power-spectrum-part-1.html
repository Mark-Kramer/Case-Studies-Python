<!DOCTYPE html>
<html lang="en">
  

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>The Power Spectrum (Part 1)</title>
  <meta name="description" content="Analysis of rhythmic activity for the practicing neuroscientist">

  <link rel="canonical" href="https://eschlaf2.github.io/Case-Studies-Python/03/the-power-spectrum-part-1.html">
  <link rel="alternate" type="application/rss+xml" title="Case Studies in Neural Data Analysis" href="https://eschlaf2.github.io/Case-Studies-Python/feed.xml">

  <meta property="og:url"         content="https://eschlaf2.github.io/Case-Studies-Python/03/the-power-spectrum-part-1.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="The Power Spectrum (Part 1)" />
<meta property="og:description" content="Analysis of rhythmic activity for the practicing neuroscientist" />
<meta property="og:image"       content="" />


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage":
    "https://eschlaf2.github.io/Case-Studies-Python/03/the-power-spectrum-part-1.html",
  "headline":
    "The Power Spectrum (Part 1)",
  "datePublished":
    "2019-04-24T21:59:58-04:00",
  "dateModified":
    "2019-04-24T21:59:58-04:00",
  "description":
    "Analysis of rhythmic activity for the practicing neuroscientist",
  "author": {
    "@type": "Person",
    "name": "Mark Kramer and Uri Eden"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://eschlaf2.github.io/Case-Studies-Python",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://eschlaf2.github.io/Case-Studies-Python",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/Case-Studies-Python/assets/css/styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css ">
  <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/Case-Studies-Python/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    CommonHTML: {
        linebreaks: {
            automatic: true,
        },
    },
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/Case-Studies-Python';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="/Case-Studies-Python/assets/js/anchor.min.js"  type="text/javascript"></script>
  <script>

initFunction(function () {
    anchors.add("main h1, main h2, main h3, main h4")
});

</script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="/Case-Studies-Python/assets/js/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  <script src="https://unpkg.com/nbinteract-core" async></script>

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->

<script type="text/x-thebe-config">
    {
      requestKernel: true,
      binderOptions: {
        repo: 'eschlaf2/Case-Studies-Python',
        ref: 'master',
      },
      kernelOptions: {
        name: 'python3',
      }
    }
</script>
<script src="https://unpkg.com/thebelab@0.3.3/lib/index.js"></script>
<script>
    /**
     * Add attributes to Thebelab blocks
     */

    const initThebelab = () => {
        const addThebelabToCodeCells = () => {
            console.log("Adding thebelab to code cells...");
            // If Thebelab hasn't loaded, wait a bit and try again. This
            // happens because we load ClipboardJS asynchronously.
            if (window.thebelab === undefined) {
                setTimeout(addThebelabToCodeCells, 250)
            return
            }

            // If we already detect a Thebelab cell, don't re-run
            if (document.querySelectorAll('div.thebelab-cell').length > 0) {
                return;
            }

            // Find all code cells, replace with Thebelab interactive code cells
            const codeCells = document.querySelectorAll('.input_area pre')
            codeCells.forEach((codeCell, index) => {
                const id = codeCellId(index)
                codeCell.setAttribute('data-executable', 'true')

                // Figure out the language it uses and add this too
                var parentDiv = codeCell.parentElement.parentElement;
                var arrayLength = parentDiv.classList.length;
                for (var ii = 0; ii < arrayLength; ii++) {
                    var parts = parentDiv.classList[ii].split('language-');
                    if (parts.length === 2) {
                        // If found, assign dataLanguage and break the loop
                        var dataLanguage = parts[1];
                        break;
                    }
                }
                codeCell.setAttribute('data-language', dataLanguage)

                // If the code cell is hidden, show it
                var inputCheckbox = document.querySelector(`input#hidebtn${codeCell.id}`);
                if (inputCheckbox !== null) {
                    setCodeCellVisibility(inputCheckbox, 'visible');
                }
            });

            // Remove the event listener from the page so keyboard press doesn't
            // Change page
            document.removeEventListener('keydown', initPageNav)
            keyboardListener = false;

            // Init thebelab
            thebelab.bootstrap();

            // Remove copy buttons since they won't work anymore
            const copyButtons = document.querySelectorAll('.copybtn')
            copyButtons.forEach((copyButton, index) => {
                copyButton.remove();
            });

            // Remove outputs since they'll be stale
            const outputs = document.querySelectorAll('.output *, .output')
            outputs.forEach((output, index) => {
                output.remove();
            });
        }

        // Add event listener for the function to modify code cells
        const thebelabButton = document.getElementById('interact-button-thebelab');
        if (thebelabButton === null) {
            setTimeout(initThebelab, 250)
        return
        };
        thebelabButton.addEventListener('click', addThebelabToCodeCells);
    }

    // Initialize Thebelab
    initFunction(initThebelab);
</script>


  <!-- Google analytics -->
  <script src="/Case-Studies-Python/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" async></script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const codeCellId = index => `codecell${index}`

const clipboardButton = id =>
  `<a class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/Case-Studies-Python/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  const codeCells = document.querySelectorAll('div.highlighter-rouge:not(.output) pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.querySelector(`pre#${id} + a`) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>

  <!-- Hide cell code -->
  
<script>
/**
Add buttons to hide code cells
*/


var setCodeCellVisibility = function(inputField, kind) {
    // Update the image and class for hidden
    var id = inputField.getAttribute('data-id');
    var codeCell = document.querySelector(`#${id}`);

    if (kind === "visible") {
        codeCell.classList.remove('hidden');
        inputField.checked = true;
    } else {
        codeCell.classList.add('hidden');
        inputField.checked = false;
    }
}

var toggleCodeCellVisibility = function (event) {
    // The label is clicked, and now we decide what to do based on the input field's clicked status
    if (event.target.tagName === "LABEL") {
        var inputField = event.target.previousElementSibling;
    } else {
        // It is the span inside the target
        var inputField = event.target.parentElement.previousElementSibling;
    }

    if (inputField.checked === true) {
        setCodeCellVisibility(inputField, "visible");
    } else {
        setCodeCellVisibility(inputField, "hidden");
    }
}


// Button constructor
const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

var addHideButton = function () {
  // If a hide button is already added, don't add another
  if (document.querySelector('div.hidecode input') !== null) {
      return;
  }

  // Find the input cells and add a hide button
  document.querySelectorAll('div.input_area div.highlight').forEach(function (item, index) {
    if (!item.parentElement.classList.contains("hidecode")) {
        // Skip the cell if it doesn't have a hidecode class
        return;
    }

    const id = codeCellId(index)
    item.setAttribute('id', id);
    item.insertAdjacentHTML('afterend', hideCodeButton(id))

    // Set up the visibility toggle
    hideLink = document.querySelector(`#${id} + input + label`);
    hideLink.addEventListener('click', toggleCodeCellVisibility)
  });
}


// Initialize the hide buttos
var initHiddenCells = function () {
    // Add hide buttons to the cells
    addHideButton();

    // Toggle the code cells that should be hidden
    document.querySelectorAll('div.hidecode input').forEach(function (item) {
        setCodeCellVisibility(item, 'hidden');
        item.checked = true;
    })
}

initFunction(initHiddenCells);

</script>


  <!-- Load custom website scripts -->
  <script src="/Case-Studies-Python/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/Case-Studies-Python/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/Case-Studies-Python/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("https://eschlaf2.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="/Case-Studies-Python/assets/js/lunr/lunr.min.js" type="text/javascript"></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>
</head>

  <body>
    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://jupyter.org/jupyter-book/intro.html"><img src="/Case-Studies-Python/images/logo/logo.png" class="textbook_logo" id="sidebar-logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">Case Studies in Neural Data Analysis</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/Case-Studies-Python/intro.html"
        >
          
          Home
        </a>

        
      </li>

      
    
      
      
        <li class="c-sidebar__chapter"><a class="c-sidebar__entry" href="/Case-Studies-Python/search.html">Search</a></li>
        
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="https://github.com/Mark-Kramer/Case-Studies-Python.git"
        >
          
          GitHub repository
        </a>

        
      </li>

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      
        <li><h2 class="c-sidebar__title">Contents</li>
        
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/Case-Studies-Python/01/Intro.html"
        >
          
            1.
          
          Introduction to Python
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/Case-Studies-Python/02/the-event-related-potential.html"
        >
          
            2.
          
          The Event-Related Potential
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry c-sidebar__entry--active"
          href="/Case-Studies-Python/03/the-power-spectrum-part-1.html"
        >
          
            3.
          
          The Power Spectrum (Part 1)
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections ">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/Case-Studies-Python/03/supplement-1.html"
                >
                  
                    3.1
                  
                  Biased versus unbiased autocovariance
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/Case-Studies-Python/03/supplement-2.html"
                >
                  
                    3.2
                  
                  Intuition behind the power spectral density
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/Case-Studies-Python/04/the-cross-covariance-and-coherence.html"
        >
          
            4.
          
          The Cross Covariance and Coherence
        </a>

        
      </li>

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

      
      <!-- Shamelessly copied from minimal mistakes -->


<!-- TOC will only show up if it has at least one item -->


  <aside class="sidebar__right">
    <nav class="onthispage">
      <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
      <ul class="toc__menu">
  <li><a href="#summary">Summary</a></li>
  <li><a href="#on-ramp-computing-the--spectrum-in-python">On-ramp: computing the  spectrum in Python</a></li>
  <li><a href="#introduction">Introduction</a>
    <ul>
      <li><a href="#case-study-data">Case study data</a></li>
      <li><a href="#goals">Goals</a></li>
      <li><a href="#tools">Tools</a></li>
    </ul>
  </li>
  <li><a href="#data-analysis">Data analysis</a>
    <ul>
      <li><a href="#step-1-visual-inspection">Step 1: Visual inspection</a></li>
      <li><a href="#step-2-mean-variance-and-standard-deviation">Step 2: Mean, variance, and standard deviation</a></li>
      <li><a href="#step-3-the-autocovariance">Step 3: The autocovariance</a></li>
      <li><a href="#step-4-power-spectral-density-or-spectrum">Step 4: Power spectral density, or spectrum</a></li>
      <li><a href="#discrete-fourier-transform-in-python-">Discrete Fourier Transform in Python </a></li>
      <li><a href="#the-frequency-resolution-df">The frequency resolution, $df$</a></li>
      <li><a href="#step-5-decibel-scaling">Step 5: Decibel scaling</a></li>
      <li><a href="#step-6-the-spectrogram">Step 6: The spectrogram</a></li>
    </ul>
  </li>
</ul>
    </nav>
  </aside>


      
      <main class="c-textbook__page" tabindex="-1">
          <div class="o-wrapper">
            <div class="c-sidebar-toggle">
  <!-- We show the sidebar by default so we use .is-active -->
  <button
    id="js-sidebar-toggle"
    class="hamburger hamburger--arrowalt is-active"
  >
    <span class="hamburger-box">
      <span class="hamburger-inner"></span>
    </span>
    <span class="c-sidebar-toggle__label">Toggle Sidebar</span>
  </button>
</div>

            
<div class="buttons">
<a href="/Case-Studies-Python/content/03/the-power-spectrum-part-1.ipynb" download>
<button id="interact-button-download" class="interact-button">Download</button>
</a>

<button id="interact-button-thebelab" class="interact-button">Thebelab</button>








<a href="https://mybinder.org/v2/gh/eschlaf2/Case-Studies-Python/master?filepath=content%2F03%2Fthe-power-spectrum-part-1.ipynb"><button class="interact-button" id="interact-button-binder"><img class="interact-button-logo" src="/Case-Studies-Python/assets/images/logo_binder.svg" alt="Interact" />Interact</button></a>


</div>


            <div class="c-textbook__content">
              <p><a id="top"></a></p>
<h1 id="analysis-of-rhythmic-activity-for-the-practicing-neuroscientist">Analysis of rhythmic activity <em>for the practicing neuroscientist</em></h1>

<div class="alert alert-block alert-info">
  <p><em><strong>Synopsis</strong></em> <br /><br /></p>

  <p><strong>Data:</strong> 2 s of scalp EEG data sampled at 1000 Hz.<br /></p>

  <p><strong>Goal:</strong> Characterize the observed rhythms in these data.<br /></p>

  <p><strong>Tools:</strong> Fourier transform, power spectral density, spectrogram.</p>
</div>

<ul>
  <li><a href="#.">Introduction</a></li>
  <li><a href="#data-analysis">Data analysis</a>
    <ol>
      <li><a href="#visual-inspection">Visual inspection</a></li>
      <li><a href="#mean">Mean, variance, and standard deviation</a></li>
      <li><a href="#autocovariance">The autocovariance</a></li>
      <li><a href="#power-spectral-density">Power spectral density</a>
        <ul>
          <li><a href="#spectrum">The spectrum</a></li>
          <li><a href="#dft">The discrete Fourier transform in Python</a></li>
          <li><a href="#nyquist-frequency">The Nyquist frequency</a></li>
          <li><a href="#frequency-resolution">The frequency resolution</a></li>
        </ul>
      </li>
      <li><a href="#decibel-scaling">Decibel scaling</a></li>
      <li><a href="#the-spectrogram">The spectrogram</a></li>
    </ol>
  </li>
  <li>
    <h2 id="summary"><a href="#summary">Summary</a></h2>
  </li>
  <li><a href="Supplement.%20Biased%20versus%20unbiased%20autocovariance.ipynb">Supplement: Biased versus unbiased autocovariance</a></li>
  <li><a href="Supplement.%20Intuition%20behind%20the%20power%20spectral%20density.ipynb">Supplement: Intuition behind the power spectral density</a></li>
</ul>

<h2 id="on-ramp-computing-the--spectrum-in-python">On-ramp: computing the  spectrum in Python</h2>
<p>We begin this module with an “<em>on-ramp</em>” to analysis. The purpose of this on-ramp is to introduce you immediately to a core concept in this module: how to compute a spectrum in Python. You may not understand all aspects of the program here, but that’s not the point. Instead, the purpose of this on-ramp is to illustrate what <em>can</em> be done. Our advice is to simply run the code below and see what happens …</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Prepare the modules and plot settings</span>
<span class="kn">import</span> <span class="nn">scipy.io</span> <span class="k">as</span> <span class="n">sio</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">sio</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="s">'EEG-1.mat'</span><span class="p">)</span>    <span class="c"># Load the EEG data</span>
<span class="n">EEG</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'EEG'</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>      <span class="c"># Extract the EEG variable</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'t'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   <span class="c"># ... and the t variable</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">EEG</span>                            <span class="c"># Relabel the data variable</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                   <span class="c"># Define the sampling interval</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                     <span class="c"># Define the total number of data points</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">N</span> <span class="o">*</span> <span class="n">dt</span>                         <span class="c"># Define the total duration of the data</span>

<span class="n">xf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>               <span class="c"># Compute Fourier transform of x</span>
<span class="n">Sxx</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">T</span> <span class="o">*</span> <span class="p">(</span><span class="n">xf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">xf</span><span class="p">))</span>  <span class="c"># Compute spectrum</span>
<span class="n">Sxx</span> <span class="o">=</span> <span class="n">Sxx</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>                 <span class="c"># Ignore negative frequencies</span>

<span class="n">df</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">T</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>                            <span class="c"># Determine frequency resolution</span>
<span class="n">fNQ</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">dt</span> <span class="o">/</span> <span class="mi">2</span>                            <span class="c"># Determine Nyquist frequency</span>
<span class="n">faxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">fNQ</span><span class="p">,</span><span class="n">df</span><span class="p">)</span>                 <span class="c"># Construct frequency axis</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">faxis</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">Sxx</span><span class="p">))</span>               <span class="c"># Plot spectrum vs frequency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>                          <span class="c"># Select frequency range</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Frequency [Hz]'</span><span class="p">)</span>                <span class="c"># Label the axes</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Power [$</span><span class="err">\</span><span class="s">mu V^2$/Hz]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_4_0.png" alt="png" /></p>

<p><strong>Q:</strong> Try to read the code above. Can you see how it loads data, computes the spectrum, and then plots the results?</p>

<p><strong>A:</strong> If you’ve never computed a spectrum before, that’s an especially difficult question. Please continue on to learn this <strong>and more</strong>!</p>

<h2 id="introduction">Introduction</h2>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'PmGme7YuAiw'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/PmGme7YuAiw" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>In this module, we consider data recorded in the scalp <a href="https://en.wikipedia.org/wiki/Electroencephalography">electroencephalogram</a> or EEG. The EEG provides a measure of brain voltage activity with high temporal resolution (typically on the order of milliseconds) but poor spatial resolution (on the order of 10 cm<sup>2</sup> of cortex). Here we will consider EEG activity recorded from a single scalp electrode. We will analyze these data to determine what (if any) rhythmic activity is present. In doing so, we will learn about an important technique to characterize rhythms in data - the Fourier transform and power spectral density or “spectrum” - and the many subtleties associated with this technique. We begin with a brief description of the data.</p>

<h3 id="case-study-data">Case study data</h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'oRCUx11iEck'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/oRCUx11iEck" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>A patient enters the Massachusetts General Hospital (MGH) emergency room unconscious. As part of his clinical workup, electrodes are placed on the scalp surface and the EEG recorded. We assume that the skilled technicians at MGH record the EEG data with no artifacts (i.e., correctly placed electrodes in good electrical contact with the scalp). Twenty-one electrodes simultaneously record the EEG data for 10 minutes sampled at 1000 Hz (i.e., 1000 samples per second). To start, we receive from our clinical collaborator a 2 s snippet of EEG data recorded from a single electrode:
<a href="#fig:3.1" class="fig"><span><img src="imgs/3-1.png" /></span></a>
If we find anything interesting in this 2 s snippet, our clinical collaborator has promised to provide additional EEG data from this patient and others.</p>

<h3 id="goals">Goals</h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'L0xf0dCn7T0'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/L0xf0dCn7T0" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>The goal of this chapter is to analyze the 2 s of EEG data by characterizing the observed rhythms. By the end of this chapter, you should be familiar with the principles of the Fourier transform, how to compute the spectrum in Python, and the time-windowed spectrum.</p>

<h3 id="tools">Tools</h3>
<p>The primary tool developed in this chapter is the Fourier transform. We will learn how to compute the Fourier transform, and the associated spectrum, in Python. We will see that the spectrum provides a powerful technique to assess rhythmic structure in time series data.</p>

<h2 id="data-analysis">Data analysis<a id="data-analysis"></a></h2>

<p>We will go through the following steps to analyze the data:</p>

<ol>
  <li><a href="#visual-inspection">Visual inspection</a></li>
  <li><a href="#mean">Mean, variance, and standard deviation</a></li>
  <li><a href="#autocovariance">The autocovariance</a></li>
  <li><a href="#power-spectral-density">Power spectral density</a></li>
  <li><a href="#decibel-scaling">Decibel scaling</a></li>
  <li><a href="#the-spectrogram">The spectrogram</a></li>
</ol>

<h3 id="step-1-visual-inspection">Step 1: Visual inspection<a id="visual-inspection"></a></h3>

<p>Before we begin, let’s set up our notebook:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Prepare the modules and plot settings</span>
<span class="kn">import</span> <span class="nn">scipy.io</span> <span class="k">as</span> <span class="n">sio</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">import</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">plot</span><span class="p">,</span> <span class="n">show</span><span class="p">,</span> <span class="n">title</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<p>Often, the best place to begin our data analysis is visual inspection of the time series. To do so, let’s plot the data:<a id="fig:3.1"></a></p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">sio</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="s">'EEG-1.mat'</span><span class="p">)</span>    <span class="c"># Load the EEG data</span>
<span class="n">EEG</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'EEG'</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>      <span class="c"># Extract the EEG variable</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'t'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>                   <span class="c"># ... and the t variable</span>

<span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">EEG</span><span class="p">)</span>                       <span class="c"># Plot the data versus time</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Time [s]'</span><span class="p">)</span>                 <span class="c"># Label the time axis</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Voltage [$</span><span class="err">\</span><span class="s">mu V$]'</span><span class="p">)</span>        <span class="c"># ... and the voltage axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">autoscale</span><span class="p">(</span><span class="n">tight</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>          <span class="c"># Minimize white space</span>
<span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_20_0.png" alt="png" /></p>

<div class="alert alert-block alert-warning">
  <p><strong>Array shapes:</strong> The <code class="highlighter-rouge">reshape()</code> function lets us change the shape of an array. <code class="highlighter-rouge">reshape(-1)</code> tells Python to reshape the array into a vector with as many elements as are in the array. Mathematically, a vector is a one-dimensional array. In Python, the difference is that a vector is indexed by a single number, while an array is indexed by multiple numbers. After reshaping, we can look at the number at index 0 of <code class="highlighter-rouge">EEG</code> using <code class="highlighter-rouge">EEG[0]</code>. If we don’t reshape first, we need to use <code class="highlighter-rouge">EEG[0, 0]</code> to get the same result, so reshaping the array isn’t required, but it is more convenient. There is a nice explanation of array shapes <a href="https://stackoverflow.com/questions/22053050/difference-between-numpy-array-shape-r-1-and-r#answer-22074424">here</a>.</p>
</div>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> What observations can you make about the EEG data?</p>
</div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'GepHsNVXTN4'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/GepHsNVXTN4" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>You might notice, through visual inspection, a dominant rhythmic activity. We can approximate the frequency of this rhythm by counting the number of oscillations that occur in a 1 s interval. To do so, we might count the total number of maxima and divide by 2 (because we observe 2 seconds of data). However, counting so many maxima over an extended time interval is quite an error-prone procedure. Instead, let us count the number of maxima in the first 0.2 s, and then multiply by five; that will approximate the total number of peaks in a 1 s interval. We count about 12 peaks in the first 0.2 s, which corresponds to approximately 60 peaks in 1 s. That’s (approximately) 60 cycles per second or 60 Hertz (Hz).</p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> What if you counted the minima, instead of the maxima? Do you get the same answer? What if you counted the zero crossings?</p>
</div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'mZ1uHN4lcPY'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/mZ1uHN4lcPY" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>Visual inspection suggests a dominant rhythmic activity at a frequency of 60 Hz. With excitement we recall that high frequency oscillations in the 40-80 Hz band (the “<a href="https://en.wikipedia.org/wiki/Gamma_wave">gamma band</a>”) are thought important for cognitive processing in the brain [<a href="https://www.ncbi.nlm.nih.gov/pubmed/23287106">Nikolić, Fries, &amp; Singer, 2013</a>]. But, there’s a reason for the label gamma band: the rhythmic activity observed <em>in vivo</em> is typically diffuse, spread over a range of rhythms at neighboring frequencies. The rhythmic activity observed here is concentrated and remarkably regular for EEG data.</p>

<div class="alert alert-block alert-success">
  <p><strong>Important fact:</strong> The alternating current in any North American electrical socket alternates at 60 Hz.</p>
</div>

<p>We conclude that the data are dominated by electrical noise and continue with additional analysis, beyond visual inspection of the time series data. Our visual inspection suggests a dominant 60 Hz signal, but perhaps something else is there, lurking in the signal background.</p>

<p>Sometimes visual inspection is enough, especially when something has gone wrong (e.g., if the EEG trace were zero for all time, we should be suspicious). But, looks can be deceiving. For one, the voltage trace is plotted as a continuous line, but that’s incorrect. If we look more closely, we find that the data consists of discrete points.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'UVnpQVUqpWI'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/UVnpQVUqpWI" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="mi">25</span><span class="p">],</span> <span class="n">EEG</span><span class="p">[:</span><span class="mi">25</span><span class="p">],</span> <span class="s">'o-'</span><span class="p">)</span>    <span class="c"># Plot the first 25 points of data,</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Time [s]'</span><span class="p">)</span>              <span class="c"># ... with axes labeled.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Voltage [$</span><span class="err">\</span><span class="s">mu V$]'</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_28_0.png" alt="png" /></p>

<p>Although the true brain signal may evolve as a continuous voltage trace in time, we do not observe this true signal. Instead, we observe a discrete sampling of this signal in time. The spacing between these samples is determined by the recording device collecting the EEG data. In this case, our collaborator has told us that the data are sampled at 1000 Hz, which corresponds to a sample of data every 1 ms. So, we observe not the (presumably) continuous true voltage signal, but instead discrete samples of this signal in time.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'W9BTYZM8yzs'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/W9BTYZM8yzs" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>To understand the impact of this discrete sampling, we first require some definitions. Let’s define $\Delta$ as the time between samples, in this case, $\Delta = 1$ ms. We also define $N$ as the total number of points observed, and $T$ as the total time of the recording. These three terms are related:</p>

<p>$T = N \Delta$.</p>

<p>For the $T = 2$ s of EEG data, there are $N = T/dt = 2/0.001 = 2000$ points. From this, we can also define the <strong>sampling frequency</strong></p>

<p>$f_0 = 1/\Delta$</p>

<p>which in this case is 1000 Hz. Finally, we define a symbol for the data, $x$, which we also write as $x_n$ to explicitly indicate the index $n \in {1, 2, 3, \ldots, N}$ corresponding to the sample number. Let’s also define all of these variables in Python:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">EEG</span>           <span class="c"># Relabel the data variable</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c"># Define the sampling interval</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    <span class="c"># Define the total number of data points</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">N</span> <span class="o">*</span> <span class="n">dt</span>        <span class="c"># Define the total duration of the data</span>
</code></pre></div></div>

<p>We will need to keep the sampling interval $\Delta$ and the total recording duration $T$ in mind—both will serve fundamental roles in our characterization of the rhythmic activity.</p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> In the second line of the code above we define the sampling interval as <code class="highlighter-rouge">dt = t[1] - t[0]</code>. How else could we have defined <code class="highlighter-rouge">dt</code>? Would <code class="highlighter-rouge">t[10] - t[9]</code> be appropriate?</p>
</div>

<p><a href="#top">Return to top</a></p>

<h3 id="step-2-mean-variance-and-standard-deviation">Step 2: Mean, variance, and standard deviation<a id="mean"></a></h3>

<p>As a first step in our analysis of the EEG data, let’s define two of the simplest measures we can use to characterize data $x$: the mean and variance <sup><abbr title="We could instead write the sample mean, because we use the observed data to estimate the theoretical mean that we would see if we were to keep repeating this experiment. This distinction is not essential to our goals here, but is important when talking to your statistics-minded colleagues. Throughout this chapter and others, we omit the term “sample” when referring to sample means, variances, covariances, and so forth, unless this distinction becomes essential to our discussion."><em>note</em></abbr></sup>. To estimate the mean $\bar x$, or average value, of $x$ we compute,</p>

<p title="Mean"><script type="math/tex">\bar x = \frac{1}{N}\sum_{n=1}^N x_n.</script></p>

<p>In words, we sum the values of $x$ for all $n$ time indices, then divide by the total number of points summed ($N$). To estimate the variance $\sigma^2$ of $x$ we compute,</p>

<p title="Variance">
<script type="math/tex">\sigma^2 = \frac{1}{N}\sum_{n=1}^N (x_n - \overline x)^2,</script>
</p>

<p>which characterizes the extent of fluctuations about the mean. The <em>standard deviation</em> is simply the square root of the variance (i.e., $\sigma$). It’s straightforward to compute all three quantities on an <code class="highlighter-rouge">ndarray</code> in Python:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mn</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>  <span class="c"># Compute the mean of the data</span>
<span class="n">vr</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>   <span class="c"># Compute the variance of the data</span>
<span class="n">sd</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>   <span class="c"># Compute the standard deviation of the data</span>

<span class="k">print</span><span class="p">(</span><span class="s">'mn = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">mn</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'vr = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">vr</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'sd = '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sd</span><span class="p">))</span>
</code></pre></div></div>

<div class="output output_stream highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mn = 2.731148640577885e-17
vr = 0.5047172407856452
sd = 0.7104345436320261

</code></pre></div></div>

<div class="alert alert-block alert-warning">
  <p><strong>A note on data types:</strong> As used above, <code class="highlighter-rouge">mean()</code>, <code class="highlighter-rouge">var()</code>, and <code class="highlighter-rouge">std()</code> are methods of a type of variable called an <em>ndarray</em> (use <code class="highlighter-rouge">type(x)</code> to see what type of variable <code class="highlighter-rouge">x</code> is). The SciPy <code class="highlighter-rouge">loadmat()</code> function automatically imports variables to this data type, but it is likely that you will end up working with other data types as well. If you find that <code class="highlighter-rouge">x.mean()</code> produces an error, <code class="highlighter-rouge">x</code> is probably not an ndarray. In this case, you should import the <code class="highlighter-rouge">numpy</code> module and either convert your variable to an ndarray using <code class="highlighter-rouge">numpy.array(x)</code>, or calculate the mean using <code class="highlighter-rouge">numpy.mean(x)</code>.</p>
</div>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> Compare the mean computed above with the plot of the EEG data. Are the two consistent? How does the standard deviation compare with the EEG fluctuations in the plot?<br /><br /></p>

  <p><strong>A.</strong> The computed mean is approximately 0. Visual inspection of the plot suggests that the EEG data fluctuate around a center value of 0, so the computed mean is consistent with our visual inspection of the data. The computed standard deviation is approximately 0.71. We expect that most of the signal fluctuations lie within two standard deviations (i.e., $\pm 2\sigma$) of the mean. We therefore expect to observe EEG values mostly between 0 ± 1.4 = (−1.4, 1.4), which is in fact what we observe.</p>
</div>

<p>The mean and variance (and standard deviation) provide single numbers that summarize the EEG trace. In this case, these numbers are not particularly useful. Both may depend on many factors, including the electrical contact between the electrode and scalp surface, and the cognitive state of the subject. Here, we’re more interested in how the EEG activity is distributed across rhythms. We’ve already begun to assess rhythms in the EEG data through visual inspection of the time series. To further characterize these rhythms, we will employ another powerful tool - the Fourier transform. However, before introducing the Fourier transform, we’ll first consider an intimately related measure: the autocovariance.</p>

<p><a href="#top">Return to top</a></p>

<h3 id="step-3-the-autocovariance">Step 3: The autocovariance<a id="autocovariance"></a></h3>

<p>Our visual inspection strongly suggests a prominent feature in the data—rhythmic activity. Rhythmic activity represents a type of dependent structure in the data. For example, if we know the data tends to oscillate near 60 Hz, then given the value of the EEG data now, we can accurately predict the value of the EEG data 1/60 s in the future (i.e., one cycle of the 60 Hz activity); it should
be similar. One technique to assess the dependent structure in the data is the autocovariance. To start, let’s write down the formula for the autocovariance, $r_{xx}[L]$, evaluated at lag $L$,</p>

<p><a id="eq:3.3"></a>
<script type="math/tex">r_{xx}[L] = \frac{1}{N}\sum_{n=1}^{N-L}(x_{n+L} - \bar x)(x_n - \bar x).</script></p>

<p>In words, the autocovariance multiplies the data $x$ at index $n + L$, by the data $x$ at index $n$, and sums these products over all indices $n$. Notice that, in both terms, the mean value $\bar x$ is subtracted from $x$ before computing the product, and we divide the resulting sum by the total number of data points in $x$. We note that this is a <em>biased</em> estimate of the autocovariance; we compare this to an unbiased estimate of the autocovariance in the supplement entitled <a href="Supplement. Biased versus unbiased autocovariance.ipynb"><em>Biased versus unbiased autocovariance</em></a>.</p>

<p>To gain some intuition for the autocovariance, let’s represent $x$ graphically as a one-dimensional row vector.</p>

<p><img src="imgs/3-3a.png" alt="cartoon of a row vector" title="We imagine the data x as a one-dimensional vector with indices n = {1,2,3,...N}." /></p>

<p>For the case $L = 0$, the autocovariance is simply the element-by-element product of x with itself, summed over all indices.</p>

<p><img src="imgs/3-3b.png" alt="autocovariance at lag 0" title="The autocovariance at lag 0. To compute the autocovariance, we sum the multiplied elements, and then divide by N (the total number of data points)." /></p>

<p>For the case $L = 1$, we shift $x$ by one index, multiply element-by-element the original (unshifted) $x$ by the shifted version, and sum over all indices.</p>

<p><img src="imgs/3-3c.png" alt="autocovariance at lag 1" title="The autocovariance at lag 1. To compute the autocovariance, we sum the multiplied elements and then divide by N (the total number of data points). Gray index labels at the beginning and end of each vector indicated data points not involved in computing the autocovariance at the chosen lag L." /></p>

<p>This process of shifting, element-by-element multiplying, and summing can be repeated for both positive and negative values of the lag $L$. Notice that, for larger values of $L$, we lose values at the beginning and ends of the autocovariance.</p>

<p><img src="imgs/3-3d.png" alt="autocovariance at lag 2" title="The autocovariance at lag 2. To compute the autocovariance, we sum the multiplied elements and then divide by N (the total number of data points). Gray index labels at the beginning and end of each vector indicated data points not involved in computing the autocovariance at the chosen lag L." /></p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> What is the largest reasonable value of $L$ to consider? For example, does a value of $L$ greater than $N$ make sense?</p>
</div>

<p>The autocovariance will be largest at the lag $L$ for which the values of x “match”. For most functions, the autocovariance is largest at $L = 0$ (of course $x$ matches itself with zero shift) and tends to decrease as the magnitude of $L$ increases. Physically, the decrease in autocovariance with lag is consistent with the notion that data becomes less similar as time progresses. For example, in an EEG recording, we expect the activity now to be similar to the activity in the immediate future, but different from the EEG activity in the more distant future; as the brain responds to different internal and external cues, we expect different EEG activities to emerge, and associations between the EEG activity now and later to decay. Functions $x$ that exhibit dependent structure possess informative features in the autocovariance, as we’ll see for the EEG data in a moment.</p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> Compare the <a href="#autocovariance">autocovariance</a> at $L=0$ and the <a href="#mean">standard deviation</a>. Notice anything similar?</p>
</div>

<p>To compute the autocovariance of the EEG data, we execute the following commands<a id="fig:3-4a"></a></p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">lags</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c"># Compute the lags for the full autocovariance vector</span>
                                      <span class="c"># ... and the autocov for L +/- 100 indices</span>
<span class="n">ac</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">correlate</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">mode</span><span class="o">=</span><span class="s">'full'</span><span class="p">)</span>
<span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">lags</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">100</span>            <span class="c"># Find the lags that are within 100 time steps</span>
<span class="n">plot</span><span class="p">(</span><span class="n">lags</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span> <span class="o">*</span> <span class="n">dt</span><span class="p">,</span> <span class="n">ac</span><span class="p">[</span><span class="n">inds</span><span class="p">])</span>       <span class="c"># ... and plot them</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Lag [s]'</span><span class="p">)</span>                     <span class="c"># ... with axes labelled</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Autocovariance'</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_45_0.png" alt="png" /></p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> Examine the plot of the autocovariance of the EEG data. What do you observe?</p>
</div>

<p>Notice that the first input to the function <code class="highlighter-rouge">correlate</code> is the EEG data with the mean subtracted (<code class="highlighter-rouge">x - mean(x)</code>). One striking feature of the autocovariance is the periodicity. A careful inspection shows that the autocovariance exhibits repeated peaks and troughs approximately every 0.0166 s.</p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> Why does the autocovariance exhibit repeated peaks and troughs approximately every 0.0166 s?<br /><br /></p>

  <p><strong>A.</strong> The autocovariance is reflective of the dominant rhythmic activity in the data. Remember that the EEG data are dominated by a 60 Hz rhythm.</p>
</div>

<p>To gain intuition for how this rhythmic activity affects the autocovariance, we can also plot examples of the EEG data <strong>aligned with different lags</strong> $L$. We’ll do so below in Python by examining different shifts of the 60 Hz cycle.</p>

<p>Let’s start by considering the case of $L=0$.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>                   <span class="c"># Choose a subset of the data to plot</span>
<span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"original"</span><span class="p">);</span>   <span class="c"># Plot the original</span>
<span class="n">L</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>                                <span class="c"># Choose the lag,</span>
                                    <span class="c"># ... and plot the shifted traces.</span>
<span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">x</span><span class="p">[[</span><span class="n">i</span> <span class="o">+</span> <span class="n">L</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inds</span><span class="p">]]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"L={}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">L</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>                        <span class="c"># Add a legend and informative title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Original time series data, and shifted by amount L"</span><span class="p">);</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_49_0.png" alt="png" /></p>

<p>At zero lag ($L = 0$), the two time series are identical. Therefore, the product</p>

<script type="math/tex; mode=display">(x_{n+0} - \bar x)(x_n - \bar x) = (x_n - \bar x)(x_n - \bar x) = (x_n - \bar x)^2</script>

<p>is non-negative for all indices $n$ (note that the product may sometimes be zero, but it’s never negative). To compute the autocovariance, we sum this product over all indices $n$, and divide by $N$, as defined in the equation for the autocovariance,</p>

<script type="math/tex; mode=display">r_{xx}[L] = \frac{1}{N}\sum_{n=1}^{N-L}(x_{n+L} - \bar x)(x_n - \bar x).</script>

<p>Because we sum many positive terms, we expect to find a large positive value for $r_{xx}[0]$. And indeed, that’s what we find; let’s print the value of the autocovariance at lag 0:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ac</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">lags</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)]</span>
</code></pre></div></div>

<div class="output output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0.50471724])
</code></pre></div></div>

<p>Let’s now consider shifting the EEG data by <strong>an integer multiple</strong> of the 60 Hz cycle. Let’s use a particular integer multiple of 2:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"original"</span><span class="p">);</span>       <span class="c"># Plot the original</span>
<span class="n">L</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">1</span><span class="o">/</span><span class="mi">60</span><span class="o">/</span><span class="n">dt</span><span class="p">);</span>                               <span class="c"># Choose the lag,</span>
                                                <span class="c"># ... and plot the shifted traces.</span>
<span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">x</span><span class="p">[[</span><span class="n">i</span> <span class="o">+</span> <span class="n">L</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inds</span><span class="p">]]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"L={}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">L</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>                                    <span class="c"># Add a legend and informative title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Original time series data, and shifted by amount L"</span><span class="p">);</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_53_0.png" alt="png" /></p>

<p>Therefore, at this lag $L$, we again expect the summed product</p>

<script type="math/tex; mode=display">(x_{n+L} - \bar x)(x_n - \bar x)</script>

<p>over all indices $n$ to be large, and to find a large positive value for $r_{xx}[L]$. To see  that’s what we find let’s print the value of the autocovariance at lag 34:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ac</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">lags</span> <span class="o">==</span> <span class="n">L</span><span class="p">)]</span>
</code></pre></div></div>

<div class="output output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0.48702814])
</code></pre></div></div>

<p>Notice that this value is positive, and near the value of the autocorrelation at lag 0. In fact, we expect the autocovariance to be large and positive whenever the lag $L$ is an integer multiple of the 60 Hz cycle (i.e., an integer multiple of 1/60 ≈ 0.0166 s); this is exactly what we find in the plot of the autocovariance, <a href="#fig:3-4a" class="fig"><span><img src="imgs/3-4a.png" /></span></a></p>

<p>Finally, let’s shift the EEG data by <strong>half</strong> of the 60 Hz cycle.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">"original"</span><span class="p">);</span>       <span class="c"># Plot the original</span>
<span class="n">L</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="mi">1</span><span class="o">/</span><span class="mi">60</span><span class="o">/</span><span class="n">dt</span><span class="p">);</span>                             <span class="c"># Choose the lag,</span>
                                                <span class="c"># ... and plot the shifted traces.</span>
<span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">x</span><span class="p">[[</span><span class="n">i</span> <span class="o">+</span> <span class="n">L</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inds</span><span class="p">]]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"L={}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">L</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>                                    <span class="c"># Add a legend and informative title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Original time series data, and shifted by amount L"</span><span class="p">);</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_58_0.png" alt="png" /></p>

<p>We observe a different type of relationship; at this lag, let’s call it $L^∗$, positive values in the unshifted EEG correspond to negative values in the shifted EEG. Therefore, most terms in the product</p>

<script type="math/tex; mode=display">(x_{n + L^*} - \bar x)(x_n - \bar x)</script>

<p>are negative, and summing up these terms to compute the autocovariance we find a large <strong>negative</strong> value for $r_{xx}[L^*]$. To see that, let’s print the value of the autocovariance at lag 8:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ac</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">lags</span> <span class="o">==</span> <span class="mi">8</span><span class="p">)]</span>
</code></pre></div></div>

<div class="output output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-0.49007471])
</code></pre></div></div>

<p>Finally, let’s plot the autocovariance again, highlighting the lags we investigated above, at different shifts in the 60 Hz cycle</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Plot the autocovariance again, highlighting lags at 3 different shifts in the 60 Hz cycle</span>
<span class="n">inds</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lags</span><span class="p">]</span>        <span class="c"># Get the lags in a limited range</span>
<span class="n">plot</span><span class="p">(</span><span class="n">lags</span><span class="p">[</span><span class="n">inds</span><span class="p">],</span> <span class="n">ac</span><span class="p">[</span><span class="n">inds</span><span class="p">])</span>                       <span class="c"># ... and plot the autocovariance,</span>
<span class="n">L</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>                                   <span class="c"># Consider three specific lags</span>
<span class="n">plot</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">L</span><span class="p">),</span> <span class="n">ac</span><span class="p">[[</span><span class="n">l</span> <span class="ow">in</span> <span class="n">L</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lags</span><span class="p">]],</span> <span class="s">'o'</span><span class="p">)</span> <span class="c"># ... and highlight them</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Lag'</span><span class="p">)</span>                                    <span class="c"># Label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Autocovariance'</span><span class="p">);</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_62_0.png" alt="png" /></p>

<p>The autocovariance is a useful tool for assessing the dependent structure in the EEG data. Visual inspection of the EEG reveals a specific type of dependent structure - a strong rhythmic component - in the data. This dependent structure is further characterized in the autocovariance, in which the dominant 60 Hz activity manifests as periodic peaks and troughs in the autocovariance. In the next section, we consider a second tool - the spectrum - for assessing dependent structure in time series data. As we’ll see, the autocovariance and spectrum are intimately related in a remarkable way.</p>

<p><a href="#top">Return to top</a></p>

<h3 id="step-4-power-spectral-density-or-spectrum">Step 4: Power spectral density, or spectrum<a id="power-spectral-density"></a></h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'OAHpkZy6ZX8'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/OAHpkZy6ZX8" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>There are many techniques to assess rhythmic activity in the EEG data. Here, we compute the <em>power spectral density</em>, or simply the <em>spectrum</em>, of $x$ using a well-established technique, the <a href="https://en.wikipedia.org/wiki/Fourier_transform"><em>Fourier transform</em></a>. There are many subtleties associated with computing and interpreting the spectrum. We explore some of them here; in doing so, we build our intuition for spectral analysis and our ability to deal with future, unforeseen circumstances in other data we encounter in research.</p>

<div class="alert alert-block alert-success">
  <p>The <em>spectrum</em> of the data $x$ is the magnitude squared of the Fourier transform of $x$. The spectrum indicates the amplitude of rhythmic activity in $x$ as a function of frequency.</p>

  <p>The <em>power spectral density</em> describes the extent to which sinusoids of a single frequency capture the structure of the data. To compute the power over any range of frequencies, we would integrate (or for discrete frequencies, sum) the spectrum over that frequency range.</p>

</div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'iPUpMS79xgo'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/iPUpMS79xgo" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p><a id="spectrum"></a>
<strong>Computing the spectrum.</strong> We start by presenting all the formulas and code necessary to compute the spectrum of the data. Then throughout the rest of this module, we circle back and consider each step of the computation in detail.</p>

<p>We first need a formula for the discrete-time Fourier transform of the data x:<a id="eq:3.8"></a></p>

<script type="math/tex; mode=display">X_j = \sum_{n=1}^N x_n \exp(-2 \pi i f_j t_n).</script>

<p>The Fourier transform computes the sum over all the time indices $t_n = \Delta{1, 2, 3, …, N}$ of the data $x_n$ multiplied by sinusoids oscillating at a given frequency $f_j = j / T$, where $j = {N/2 + 1, -N/2 + 2, …, N/2 - 1, N/2}$. The result is a new quantity $X_j$, the signal as a function of frequency $f_j$ rather than time $t_n$. The spectrum is then <a id="eq:3.9"></a></p>

<script type="math/tex; mode=display">S_{xx, j} = \frac{2\Delta^2}{T}X_j X_j^*,</script>

<p>which is the product of the Fourier transfrom of $x$ with its complex conjugate (indicated by the superscript $*$), scaled by the sampling interval and the total duration of the recording. The term $2\Delta^2/T$ is simply a numerical scaling. The units of the spectrum are, in this case, ($\mu$V)$^2/$Hz. Computing the spectrum in Python requires only a few lines of code:<a id="fig:3.6"></a></p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>               <span class="c"># Compute Fourier transform of x</span>
<span class="n">Sxx</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">T</span> <span class="o">*</span> <span class="p">(</span><span class="n">xf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">xf</span><span class="p">))</span>  <span class="c"># Compute spectrum</span>
<span class="n">Sxx</span> <span class="o">=</span> <span class="n">Sxx</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span>                 <span class="c"># Ignore negative frequencies</span>

<span class="n">df</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">T</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span>                            <span class="c"># Determine frequency resolution</span>
<span class="n">fNQ</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">dt</span> <span class="o">/</span> <span class="mi">2</span>                            <span class="c"># Determine Nyquist frequency</span>
<span class="n">faxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">fNQ</span><span class="p">,</span><span class="n">df</span><span class="p">)</span>                 <span class="c"># Construct frequency axis</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">faxis</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">Sxx</span><span class="p">))</span>               <span class="c"># Plot spectrum vs frequency</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>                          <span class="c"># Select frequency range</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Frequency [Hz]'</span><span class="p">)</span>                    <span class="c"># Label the axes</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Power [$</span><span class="err">\</span><span class="s">mu V^2$/Hz]'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_70_0.png" alt="png" /></p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'kmHCCzAbMVI'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/kmHCCzAbMVI" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>That’s not so bad; the code to compute and display the spectrum fits in 13 lines (with spacing for aesthetics). Notice the large peak at 60 Hz. This peak is consistent with our visual inspection of the EEG data, in which we approximated a dominant rhythm at 60 Hz by counting the number of peaks that appeared in the voltage traces. So, our computation of the spectrum at least matches our initial expectation deduced from visual inspection of the data.</p>

<p>We’ve managed to compute and plot the spectrum, and our analysis results match our expectations. We could choose to stop here. But a danger persists: we’ve blindly entered Python code and achieved an expected result. What are the frequency resolution and Nyquist frequency mentioned in the comments of the code? Maybe this procedure is fraught with pitfalls, and we simply got lucky in this case? Does the spectrum provide additional information that was not immediately uncovered? How will we react and adapt when the spectrum results do not match our intuition? To answer these questions requires developing more intuition for the Fourier transform and spectrum.</p>

<p>In a <a href="Supplement.%20Intuition%20behind%20the%20power%20spectral%20density.ipynb">supplement to this chapter</a>, we examine equations for the Fourier transform <a href="#eq:3.8" class="thumb"><span><img src="imgs/eq3-8.png" /></span></a> and spectrum <a href="#eq:3.9" class="thumb"><span><img src="imgs/eq3-9.png" /></span></a> and the Python code for computing these quantities. In doing so, we explore some subtleties of this measure and strengthen our intuition for this measure’s behavior. Building this intuition is perhaps the most important part of dealing with unforeseen circumstances arising in your own data. If this is your first time thinking about the spectrum or Fourier transform, we recommend that you take a moment to read the supplement.</p>

<h3 id="discrete-fourier-transform-in-python-">Discrete Fourier Transform in Python <a id="dft"></a></h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'noCOC69jvh8'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/noCOC69jvh8" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>Computing the spectrum of a signal $x$ in Python can be achieved in two simple steps. The first step is to compute the Fourier transform of $x$:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">EEG</span>
<span class="n">xf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
</code></pre></div></div>

<p>We subtract the mean from <code class="highlighter-rouge">x</code> before computing the Fourier transform. This is not necessary but often useful. For these neural data, we’re not interested in the very slow (0 Hz) activity; instead, we’re interested in rhythmic activity. By subtracting the mean, we eliminate this low-frequency activity from the subsequent analysis.</p>

<p>The second step is to compute the spectrum, the Fourier transform of $x$ multiplied by its complex conjugate:<a id="fig:3.10"></a></p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Sxx</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">T</span> <span class="o">*</span> <span class="p">(</span><span class="n">xf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">xf</span><span class="p">))</span>
<span class="n">plot</span><span class="p">(</span><span class="n">Sxx</span><span class="p">)</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Indices'</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Power [$</span><span class="err">\</span><span class="s">mu V^2$/Hz]'</span><span class="p">);</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_78_0.png" alt="png" /></p>

<p>Upon examining the horizontal axis in this plot, we find it corresponds to the indices of <code class="highlighter-rouge">x</code>, beginning at index 0 and ending at index <code class="highlighter-rouge">N = 1000</code>. To convert the x-axis from indices to frequencies, we need to define two new quantities:</p>

<ul>
<li> the **frequency resolution**, $df = \frac{1}{T}$, or the reciprocal of the total recording duration;</li>
<li> the **Nyquist frequency**, $f_{NQ} = \frac{f_0}{2} = \frac{1}{2\Delta}$, or half of the sampling frequency $f_0 = \frac{1}{\Delta}$.</li>
</ul>

<p>For the clinical EEG data considered here, the total recording duration is 2 s ($T = 2$ s), so the frequency resolution</p>

<script type="math/tex; mode=display">df = 1 / (2\ s) = 0.5\ Hz.</script>

<p>The sampling frequency $f_0$ is 1000 Hz, so</p>

<p><script type="math/tex">f_{NQ} = 1000 / 2\ Hz = 500\ Hz</script>.</p>

<p>There’s much more to say about both quantities, but for now let’s simply use both quantities to consider how Python relates the indices and frequencies of the vector <code class="highlighter-rouge">Sxx</code>.</p>

<div class="alert alert-block alert-warning">
  <p>When we used the <code class="highlighter-rouge">rfft</code> function we utilized a useful property of the Fourier transform. If instead of using <code class="highlighter-rouge">rfft</code> we had used <code class="highlighter-rouge">fft</code>, we would see that the vector <code class="highlighter-rouge">Sxx</code> is twice as long because the Fourier transform also calculates the spectrum for the negative frequencies. However, when a signal is real (i.e., the signal has zero imaginary component), the negative frequencies in the spectrum are redundant. So, the power we observe at frequency $f$ is identical to the power we observe at frequency $-f$. For this reason, we can safely ignore the negative frequencies; these frequencies provide no additional information. Because the EEG data are real, we conclude that the negative frequencies in the variable <code class="highlighter-rouge">Sxx</code> are redundant and can be ignored. As a specific example, the value of <code class="highlighter-rouge">Sxx</code> at index $j = 2$ is the same as the value of <code class="highlighter-rouge">Sxx</code> at index $j = 2N - 2$; these indices correspond to frequencies $2df$ and  $-2df$, respectively. We therefore need only plot the variable <code class="highlighter-rouge">Sxx</code> for the positive frequencies, more specifically, from index <code class="highlighter-rouge">0</code> to index <code class="highlighter-rouge">N</code>.</p>

</div>

<p>Given the total duration of the recording ($T$) and the sampling frequency ($f_0$) for the data, we can define the frequency axis for the spectrum <code class="highlighter-rouge">Sxx</code>. Now, to compute and plot the spectrum, we again utilize some code introduced earlier:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">Sxx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">T</span> <span class="o">*</span> <span class="p">(</span><span class="n">xf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">xf</span><span class="p">)))</span>
<span class="n">df</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">T</span>
<span class="n">fNQ</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">dt</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">faxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Sxx</span><span class="p">))</span> <span class="o">*</span> <span class="n">df</span>
<span class="n">plot</span><span class="p">(</span><span class="n">faxis</span><span class="p">,</span> <span class="n">Sxx</span><span class="p">)</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Frequency (Hz)'</span><span class="p">)</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Power [$</span><span class="err">\</span><span class="s">mu V^2$/Hz]'</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_81_0.png" alt="png" /></p>

<p>In the next two sections, we focus on interpreting and adjusting the quantities $df$ and $f_{NQ}$. Doing so is critical to developing a further intuition for the spectrum.</p>

<h4 id="the-nyquist-frequency-f_nq-">The Nyquist frequency, $f_{NQ}$ <a id="nyquist-frequency"></a></h4>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'sgYkOkrlQ_E'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/sgYkOkrlQ_E" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>The formula for the Nyquist frequency is <a id="eq:3.13"></a></p>

<script type="math/tex; mode=display">f_{NQ} = \frac{f_0}{2}.</script>

<p>The Nyquist frequency is the highest frequency we can possibly hope to observe in the data. To illustrate this, let’s consider a true EEG signal that consists of a very simple time series—a pure sinusoid that oscillates at some frequency $f_s$. Of course, we never observe the true signal. Instead, we observe a sampling of this signal, which depends on the sampling interval $\Delta$. We consider three cases for different values of $\Delta$. In the first case, we purchase a very expensive piece of equipment that can sample the true signal at a high rate, $f_0 \gg f_s$. In this case, we cover the true brain signal with many samples and given these samples, we can accurately reconstruct the underlying data.</p>

<p><a id="fig:3.11top"><img src="imgs/3-11top.png" title="A sinusoid oscillating below the Nyquist frequency. When the sampling rate is high enough, the sampled data provide a good approximation to the true data. Here, the sampling frequency is 8 times the oscillation frequency (i.e. the sinusoid is sampled eight times in each oscillation of the function)." alt="Sampling a sinusoid at a high rate." /></a></p>

<p>Now, consider the case in which we purchase a cheaper piece of equipment that samples at a maximum rate equivalent to twice the frequency of the pure sinusoid: $f_0 = 2f_s$. In this case, we might collect sufficient samples to cover the underlying signal and approximate the oscillation frequency; if the first sample resides on a peak of the sinusoid, the next sample on a trough, and so on.</p>

<p><a id="fig:3.11mid"><img src="imgs/3-11mid.png" title="A sinusoid oscillating at the Nyquist frequency. In this case we collect two samples per cycle of the underlying true signal." alt="Sampling a sinusoid at double the oscillation frequency." /></a></p>

<p>In this case, we collect two samples per cycle of the underlying true signal. Given only these sample points, we can connect the dots and still approximate the frequency fo the true underlying sinusoid.</p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> For the sampling rate $f_0 = 2f_s$, consider the case in which the first sample occurs on a zero crossing of the sinusoid. At what point does the next sample occur? and the next sample? If you connect the dots in this case, what do you find?</p>
</div>

<p>Finally, consider the case where our equipment records at a sampling rate less than the frequency of the pure sinusoid signal: $f_0 &lt; 2 f_s$.</p>

<p><a id="fig:3.11bot"><img src="imgs/3-11bot.png" title="A sinusoid oscillating above the Nyquist frequency. When the sampling rate is too low, the true high-frequency signal appears as a low-frequency oscillation." alt="Sampling a sinusoid at less than double the oscillation frequency." /></a></p>

<p>Assuming the first sample occurs at a peak of the sinusoid, the next sample occurs not at a trough (that would correspond to a sampling rate $f_0 = 2f_s$) but instead just after the trough. Connecting the samples with lines, in this case, produces something horrifying, an oscillation occurring at a different, lower frequency. Notice what has happened in this case. Sampling the sinusoid at too low a frequency (i.e., at a frequency less than twice the signal’s frequency $f_0 &lt; 2f_s$) causes this signal to manifest at a low-frequency upon sampling. This phenomenon—a high-frequency signal appearing as a low-frequency signal upon sampling—is known as <em>aliasing</em>. Once a signal has been aliased, it’s impossible to distinguish from true signals oscillating at low frequencies.</p>

<div class="alert alert-block alert-success">
  <p>To avoid aliasing, sample data at sufficiently high rates.</p>
</div>

<p>Typically, to prevent aliasing, recorded data are first analog-filtered before the digital sampling occurs. The analog filtering guarantees that activity at frequencies exceeding a threshold value ($f_c$, say) are dramatically reduced. The sampling rate can then be chosen to exceed this threshold value by at least a factor of 2 (i.e., $f_0 &gt; 2f_c$). We note that in this case the EEG data were first analog-filtered at 200 Hz before digital sampling occurred at 1000 Hz. So, for our EEG data, aliasing is not a concern.</p>

<h3 id="the-frequency-resolution-df">The frequency resolution, $df$<a id="frequency-resolution"></a></h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'bZsj_gcGoSo'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/bZsj_gcGoSo" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>The frequency resolution is defined as</p>

<script type="math/tex; mode=display">df = \frac{1}{T}</script>

<p>where $T$ is the total duration of the recording. For the EEG data used in this chapter, $T = 2$ s, so the frequency resolution is $df = 1/(2\ \mbox s) = 0.5$ Hz.</p>

<div class="alert alert-block alert-info">
  <p>
<strong>Q.</strong> How do we improve the frequency resolution?
</p>
  <p>
<strong>A.</strong> There’s only one way to do it: increase $T$. That is, record more data. For example, if we demand a frequency resolution of 0.2 Hz, how much data must we record? We can rearrange the equation to solve for $T$,
  <br />
    <script type="math/tex">T = \frac{1}{df} = \frac{1}{0.2\mbox{ Hz}} = 5\mbox{ s}</script>
  <br />
  <br />
So, record 5 s of data to obtain a frequency resolution of 0.2 Hz. 
  <br />
</p>
</div>

<div class="alert alert-block alert-info">
  <p>
<strong>Q.</strong> We estimated the spectrum in the preceding code. As we record more and more data, does the estimate of the spectrum improve?

</p>

  <p>
<strong>A.</strong> Intuitively, you might answer yes. As we collect more and more data, we usually expect our estimate of a quantity (e.g., the mean or the standard deviation) to improve. However, that is not the case for the spectrum. As we collect more and more data, we acquire more and more points along the frequency axis (i.e., $df$ becomes smaller). However, our estimate of the power at each frequency does not improve (<a href="https://www.cambridge.org/core/books/spectral-analysis-for-physical-applications/A9195239A8965A2C53D43EB2D1B80A33">Percival &amp; Walden, 1993</a>).
</p>
</div>

<p>To gain some intuition for the frequency resolution formula, consider the case in which we collect $T$ seconds of data. If the sampling interval is $\Delta$, then we collect $N = T/\Delta$ data points; for example, for the EEG data of interest here, we collect $N = 2000$ data points. We know that the number of observations in the data equals the number of frequencies in the spectrum (where we now include negative frequencies); both the data vector <code class="highlighter-rouge">x</code> and the spectrum vector <code class="highlighter-rouge">Sxx</code> have length $N$. We also know that the maximum observable frequency in the spectrum, the Nyquist frequency, is fixed no matter how much data we collect. Recall that the Nyquist frequency depends only on the sampling interval: $f_{NQ} = 1/(2\Delta)$. Now, consider the case in which we increase $T$, or equivalently, increase $N$. As we collect more and more data, the maximum frequency remains fixed at the Nyquist frequency, while the length of the spectrum vector increases. We therefore need to fit more and more frequency values between 0 Hz and the Nyquist frequency as $N$ increases.</p>

<p><a id="fig:3.12"><img src="imgs/3-12.png" alt="Cartoon representation of the relation between data and frequency resolution." /></a></p>

<p>Above we plot a cartoon representation of the relation between data and frequency resolution. Data (left) consist of different numbers of samples ($N$). As $N$ increases, the number of values on the frequency axis increases (right), the maximal frequency $(f_{NQ})$ remains fixed, and the frequency resolution ($df$) decreases. Only non-negative frequencies are shown.
This observation provides some intuition for the relation between the amount of data recorded ($T$ or $N$) and the frequency resolution ($df$).</p>

<p><a href="#top">Return to top</a></p>

<h3 id="step-5-decibel-scaling">Step 5: Decibel scaling<a id="decibel-scaling"></a></h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'SuDJha5LNL0'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/SuDJha5LNL0" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>Let’s now return to the spectrum of the EEG data.
<a href="#fig:3-6" class="fig"><span><img src="imgs/3-6.png" /></span></a>
We see that the spectrum is dominated by a single peak at 60 Hz. Other, weaker rhythmic activity may occur in the data, but these features remain hidden from visual inspection because of the large 60 Hz peak; informally, we might state that the 60 Hz peak saturates the vertical scale. One technique to emphasize lower-amplitude rhythms hidden by large-amplitude oscillations is to change the scale of the spectrum to <strong>decibels</strong>. The decibel is a logarithmic scale and easily computed as follows:
<a id="fig:3.13a"></a></p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="p">(</span><span class="n">faxis</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">Sxx</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">Sxx</span><span class="p">)))</span>   <span class="c"># Plot the spectrum in decibels.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>                           <span class="c"># Select the frequency range.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">60</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>                           <span class="c"># Select the decibel range.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Frequency [Hz]'</span><span class="p">)</span>                     <span class="c"># Label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Power [dB]'</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_96_0.png" alt="png" /></p>

<p>To change to the decibel scale, we first divide the spectrum by the maximum value observed and then take the logarithm base 10 of this ratio and multiply the result by 10. The 60 Hz rhythm is still dominant and exhibits the most power.</p>

<div class="alert alert-block alert-info">
  <p>
<strong>Q.</strong> For this example, what is the value in decibels at 60 Hz?
</p>

  <p>
<strong>A.</strong> Through our previous analysis, we know that the maximum value in the spectrum occurs at 60 Hz. By dividing the original spectrum by this maximum, we scale the spectrum at 60 Hz to a value of 1. The logarithm of 1 is 0, so we find a value of 0 at 60 Hz. Note that all other values are now smaller than 1 and therefore negative on the decibel scale.
</p>
</div>

<div class="alert alert-block alert-success">
  <p>Different conventions exist to define the decibel scale. Here we first divide by the maximum before computing the logarithm. Be sure to verify how the spectrum is scaled (if at all) to interpret the decibel axis.</p>
</div>

<p>The decibel scale reveals new structure in the spectrum. In particular, two peaks have emerged at frequencies 5–15 Hz. These peaks are much weaker than the 60 Hz signal; both peaks are approximately 30 dB below the maximum at 60 Hz, or equivalently, three <em>orders of magnitude</em> weaker. Because these peaks are so small relative to the 60 Hz signal, neither was apparent in the original plot of the spectrum.</p>

<p>To further emphasize the low-frequency structure of the spectrum, we may also convert the frequency axis to a logarithmic scale:</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="o">.</span><span class="n">semilogx</span><span class="p">(</span><span class="n">faxis</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">Sxx</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">Sxx</span><span class="p">)))</span>   <span class="c"># Log-log scale</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>                                  <span class="c"># Select frequency range</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">60</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>                                   <span class="c"># ... and the decibel range.</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Frequency [Hz]'</span><span class="p">)</span>                             <span class="c"># Label the axes.</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Power [dB]'</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_99_0.png" alt="png" /></p>

<p>Notice the change in the first line to use the <code class="highlighter-rouge">semilogx</code> function. By using the logarithmic scale to stretch the low-frequency part of the horizontal axis, the two low-frequency peaks become more apparent. The changes compared to the original spectrum are purely cosmetic. However, these cosmetic changes have proved extremely useful. The two lower-frequency peaks were originally hidden from us, both in visual inspection of the raw data and in the original plot of the spectrum. In those cases, the large-amplitude 60 Hz activity masked the smaller-amplitude (three orders of magnitude smaller) rhythms.</p>

<p><a href="#top">Return to top</a></p>

<h3 id="step-6-the-spectrogram">Step 6: The spectrogram<a id="the-spectrogram"></a></h3>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'XYy4NEr3VUs'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/XYy4NEr3VUs" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>The spectrum plotted using the decibel scale suggests that three rhythms appear in the EEG signal: 60 Hz, approximately 11 Hz, and approximately 6 Hz.<a href="#fig:3.13a" class="fig"><span><img src="imgs/3-13a.png" /></span></a> Given only these results, we may reasonably conclude that these three rhythms appear simultaneously throughout the entire 2 s of the EEG recording. That is an assumption we make in computing the spectrum of the entire 2 s interval. To further test this assumption in the EEG data, we compute a final quantity: the <em>spectrogram</em>. The idea of the spectrogram is to break up the time series into smaller intervals of data and then compute the spectrum in each interval. These intervals can be quite small and can even overlap. The result is the spectrum as a function of frequency and time.</p>

<div class="alert alert-block alert-info">
  <p><strong>Q.</strong> Consider the 2 s of EEG data. If we break up these data into smaller intervals of duration 1 s, what is the resulting frequency resolution of each interval? What is the Nyquist frequency of each interval?</p>
</div>

<p>To compute and display the spectrogram in Python, we use the (aptly named) function <code class="highlighter-rouge">spectrogram</code> from the <code class="highlighter-rouge">scipy</code> module:<a id="fig:3.14"></a></p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">signal</span>
</code></pre></div></div>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Fs</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">dt</span>               <span class="c"># Define the sampling frequency,</span>
<span class="n">interval</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">Fs</span><span class="p">)</span>        <span class="c"># ... the interval size,</span>
<span class="n">overlap</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">Fs</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">)</span>  <span class="c"># ... and the overlap intervals</span>

                          <span class="c"># Compute the spectrogram</span>
<span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">Sxx</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">spectrogram</span><span class="p">(</span>
    <span class="n">EEG</span><span class="p">,</span>                  <span class="c"># Provide the signal,</span>
    <span class="n">fs</span><span class="o">=</span><span class="n">Fs</span><span class="p">,</span>                <span class="c"># ... the sampling frequency,</span>
    <span class="n">nperseg</span><span class="o">=</span><span class="n">interval</span><span class="p">,</span>     <span class="c"># ... the length of a segment,</span>
    <span class="n">noverlap</span><span class="o">=</span><span class="n">overlap</span><span class="p">)</span>     <span class="c"># ... the number of samples to overlap,</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">Sxx</span><span class="p">),</span>
               <span class="n">cmap</span><span class="o">=</span><span class="s">'jet'</span><span class="p">)</span><span class="c"># Plot the result</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>            <span class="c"># ... with a color bar,</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">70</span><span class="p">])</span>         <span class="c"># ... set the frequency range,</span>
<span class="n">xlabel</span><span class="p">(</span><span class="s">'Time [s]'</span><span class="p">)</span>       <span class="c"># ... and label the axes</span>
<span class="n">ylabel</span><span class="p">(</span><span class="s">'Frequency [Hz]'</span><span class="p">)</span>
<span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p class="output output_png"><img src="../images/03/the-power-spectrum-part-1_107_0.png" alt="png" /></p>

<p>We supplied four arguments to the <code class="highlighter-rouge">spectrogram</code> function. Briefly, these arguments specify the data, the sampling frequency, the interval size (specified in indices and here set to 1 s), and the overlap between intervals (here set to 95%). More information about these options can be found in the documentation (<code class="highlighter-rouge">signal.spectrogram?</code>). Notice that we used <code class="highlighter-rouge">int</code> to enforce integer values for three of these inputs.</p>

<div class="alert alert-block alert-warning">
  <p>Note that in computing the spectrogram, we did not subtract the mean as we have done in the past. This is because the <code class="highlighter-rouge">spectrogram</code> function defaults to this behavior.</p>
</div>

<div class="alert alert-block alert-info">
  <p>
<strong>Q.</strong> Consider the spectrogram above. What aspects of the spectrogram are consistent with our previous results? What aspects are new? Consider, in particular, the low-frequency rhythms and the conclusions deduced from this figure compared to the plot of the spectrum. <a href="#fig:3.13a" class="fig"><span><img src="imgs/3-13a.png" /></span></a>
</p>

  <p>
<strong>A.</strong> The spectrogram displays the spectrum (in decibels) as a function of frequency (vertical axis) and time (horizontal axis). Values on the time axis indicate the center times of each 1 s window (e.g., 0.5 s corresponds to times [0, 1] s in the data). Intervals of high (low) values correspond to warm (cool) colors. Visual inspection immediately provides new insights into the observed EEG rhythms. First, we observe a band of high power at 60 Hz that persists for all time (yellow horizontal line in the plot of the spectrogram). This corresponds to the 60 Hz line noise present for the entire duration of the recording. Second, we observe intervals of increased power near 11 Hz and 6 Hz. Unlike the 60 Hz signal, the two low-frequency rhythms do not persist for the entire 2 s recording (as we may have incorrectly concluded from examination of the spectrum alone. Instead, one weak rhythm (near 6 Hz) appears for the first half of the recording, while another weak rhythm (near 11 Hz) appears for the second half of the recording. Visualization via the spectrogram of how the rhythmic activity changes in time allows this important conclusion.
</p>
</div>

<p><a href="#top">Return to top</a></p>

<h1 id="summary-">Summary <a id="summary"></a></h1>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.lib.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s">'jdceZRY_PDA'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">

        <iframe width="400" height="300" src="https://www.youtube.com/embed/jdceZRY_PDA" frameborder="0" allowfullscreen=""></iframe>
        
</div>

<p>In this chapter, we analyzed 2 s of EEG data. We started with visual inspection of the EEG time series. <a href="#fig:3.1" class="fig"><span><img src="imgs/3-1.png" /></span></a> This is always the best place to start when analyzing new data and provides initial important intuition for the time series. Through the initial visual inspection, we concluded that rhythmic activity appeared and was dominated by a 60 Hz oscillation. Then, to characterize further the rhythmic activity, we computed two related quantities: the autocovariance and the spectrum. We found that rhythmic activity appeared in the autocovariance of the data. We then considered the spectrum. To do so, we first introduced the notion of the Fourier transform and discussed in detail how to compute the spectrum in Python. We also defined two fundamental quantities—the frequency resolution and the Nyquist frequency—and explored how to manipulate these quantities. (We recommend you commit both quantities to memory. For every spectral analysis you encounter, ask: What is the frequency resolution? What is the Nyquist frequency?). We then considered how logarithmic scales can be used to emphasize features of the spectrum. <a href="#fig:3.13a" class="fig"><span><img src="imgs/3-13a.png" /></span></a> And, we examined how the spectrogram provides insight into spectral features that change in time. <a href="#fig:3.14" class="fig"><span><img src="imgs/3-14.png" /></span></a> We concluded that the EEG data are dominated by 60 Hz activity throughout the 2 s interval, and that weaker low-frequency activity emerges during two intervals: a 6 Hz rhythm from 0 s to 1 s, and an 11 Hz rhythm from 1 s to 2 s.
In this module, we only touched the surface of spectral analysis; many details and issues exist for further exploration. In future modules, we will discuss the issues of windowing and zero padding. For those interested in exploring further, see <a href="https://www.cambridge.org/core/books/spectral-analysis-for-physical-applications/A9195239A8965A2C53D43EB2D1B80A33">Percival &amp; Walden, 1998</a>, and <a href="https://www.elsevier.com/books/spectral-analysis-and-time-series-two-volume-set/priestley/978-0-08-057055-6">Priesley, 1981</a>.</p>

<p>In case you missed it earlier, details and intuition behind each step of the analysis above are provided in the supplement entitled: <a href="Supplement. Intuition behind the power spectral density.ipynb"><em>Intuition behind the power spectral density</em></a>.</p>

<div class="language-python input_area highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="n">HTML</span><span class="p">(</span><span class="s">'../style.css'</span><span class="p">)</span>
</code></pre></div></div>

<div class="output output_html">
<style>

.thumb img { 
	border:1px solid #000;
	margin:0px;
	float:center;
    background:#fff;
}
.thumb span { 
	visibility: hidden;
    width: 300px;
    background-color: black;
    color: #fff;
    text-align: center;
    border-radius: 6px;
    padding: 5px 5px;
    position: fixed;
    z-index: 1;
    bottom: 50%;
    left: 50%;
    margin-left: -150px;
    transition: 5ms visibility;
}
.thumb:hover, .thumb:hover span { 
	visibility:visible;
    transition-delay: 500ms;
		
}    
.fig img { 
	border:1px solid #000;
	margin:0px;
	float:center;
    background:#fff;
}
.fig span { 
	visibility: hidden;
    width: 500px;
    background-color: black;
    color: #fff;
    text-align: center;
    border-radius: 6px;
    padding: 5px 5px;
    position: fixed;
    z-index: 1;
    bottom: 40%;
    left: 50%;
    margin-left: -250px;
    transition: 5ms visibility;
}
.fig:hover, .fig:hover span { 
	visibility:visible;
    transition-delay: 500ms;
}
</style>


</div>


              <nav class="c-page__nav">
  
    
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/Case-Studies-Python/02/the-event-related-potential">
      〈 <span class="u-margin-right-tiny"></span> The Event-Related Potential
    </a>
  

  
    
    <a id="js-page__nav__next" class="c-page__nav__next" href="/Case-Studies-Python/03/supplement-1">
      Biased versus unbiased autocovariance <span class="u-margin-right-tiny"></span> 〉
    </a>
  
</nav>

            </div>
          </div>
        </div>
      </main>
    </div>

  </body>
</html>
