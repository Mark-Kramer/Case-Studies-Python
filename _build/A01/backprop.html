---
redirect_from:
  - "/a01/backprop"
interact_link: content/A01/backprop.ipynb
kernel_name: python3
kernel_path: content/A01
has_widgets: false
title: |-
  Backpropagation
pagenum: 11
prev_page:
  url: /11/spike-field-coherence.html
next_page:
  url: /A02/HH.html
suffix: .ipynb
search: our output weights lets input network need alert step steps neural backpropagation well value update compute choose div function code times class repeat sigmoid define w weight above procedure example initial desired block info q send feedforward through neuron x implement node start comment comments doing ask also good always try set python perform random fix calculate solution multiple activity determine here expressions derived target updates expression wed repetitions hand networks module implementing combine together create complete algorithm preliminaries text preceded indicates explain questions useful own note youve done makes sense return future its habit ill wont before beginning load

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Backpropagation</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Backpropagation">Backpropagation<a class="anchor-link" href="#Backpropagation"> </a></h1><p>In this module, we will implement the backpropagation procedure for a two-node network. We'll start by implementing each step of the backpropagation procedure, and then combine these steps together to create a complete backpropagation algorithm.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Preliminaries">Preliminaries<a class="anchor-link" href="#Preliminaries"> </a></h2><p>Text preceded by a <code>#</code> indicates a 'comment'.  I will use comments to explain what we're doing and to ask you questions.  Also, comments are useful in your own code to note what you've done (so it makes sense when you return to the code in the future).  It's a good habit to <em>always</em> comment your code.  I'll try to set a good example, but won't always . . .</p>
<p>Before beginning, let's load in the Python packages we'll need:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Steps-to-backpropagation">Steps to backpropagation<a class="anchor-link" href="#Steps-to-backpropagation"> </a></h2><p>We outlined 4 steps to perform backpropagation,</p>
<ol>
<li>Choose random initial weights.</li>
<li>Fix input at desired value, and calculate output.</li>
<li>Update the weights.</li>
<li>Repeat steps 2 &amp; 3 many times.</li>
</ol>
<p>Let's now implement these steps.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-1.-Choose-random-initial-weights.">Step 1. Choose random initial weights.<a class="anchor-link" href="#Step-1.-Choose-random-initial-weights."> </a></h2><p>This step is easy. We need to choose the three initial weights in our
  2-node model.  We can choose these weights to be anything we like,
  within reason.  Let's set:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w0</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">w1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">w2</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-block alert-info">
**Q:**  Why choose these weights?
</div><p>Then, in backpropagation, we'll update these weights so that our neural
network - when given a specific input - produces a desired output.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-2.--Fix-input-at-desired-value,-and-calculate-output.">Step 2.  Fix input at desired value, and calculate output.<a class="anchor-link" href="#Step-2.--Fix-input-at-desired-value,-and-calculate-output."> </a></h2><p>Our next step is to choose an input, send this input to our neural
  network, and compute the output.  This is called the <em>feedforward
  solution</em>; we're "feeding" our neural network the input, sending this
  input "forward" through the network, and returning the output.</p>
<p>Let's start by choosing an input,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">s0</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we need to send this input through our network. We'll do this in
  multiple steps.  First, let's compute the activity of the first neuron:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">w0</span><span class="o">*</span><span class="n">s0</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, to determine the output of the first neuron, we need to send this
  activity through a sigmoid function.  To do that, we first need to
  <em>define</em> the sigmoid function ... Let's do so here in Python,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function takes one input (<code>x</code>), and returns one output equal to the numerical
  value of the sigmoid function at that value of <code>x</code>. For example, to
  compute the value of the sigmoid function at <code>x=0.5</code>, and save this output
  in a variable <code>s</code>, we execute the following command,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.6224593312018546
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we're able to compute the output of our first neuron,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">s1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can ontinue our feedforward computation to determine the output of our neural network.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">w1</span><span class="o">*</span><span class="n">s1</span>
<span class="n">s2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">w2</span><span class="o">*</span><span class="n">s2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.36375380675182073
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-3.--Update-the-weights.">Step 3.  Update the weights.<a class="anchor-link" href="#Step-3.--Update-the-weights."> </a></h2><p>To update the weights, we'll use the expressions we derived in class 
 for the updated values of <code>w0</code> and <code>w1</code>.  Let's write those here ...</p>
<p>But first, remember that to compute the weight update, we need to define
 a learning rate,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">alpha</span>  <span class="o">=</span> <span class="mf">0.1</span>    <span class="c1">#Here we&#39;ll set the learning rate to 0.1.</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we also need to define a target value we would like our neural network to produce as output,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="mf">0.7</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, let's define two weight updates,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2</span> <span class="o">=</span> <span class="n">w2</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">out</span><span class="o">-</span><span class="n">target</span><span class="p">)</span><span class="o">*</span><span class="n">s2</span>
<span class="n">w1</span> <span class="o">=</span> <span class="n">w1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">out</span><span class="o">-</span><span class="n">target</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">w2</span><span class="o">*</span><span class="n">s2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">s2</span><span class="p">)</span><span class="o">*</span><span class="n">s1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-block alert-info">

**Q:**  Do these two expressions match the equations for the weight updates we derived in class?  HINT: They should!
</div>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need one more expression, to update the last weight, w0.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w0</span> <span class="o">=</span> <span class="s1">&#39;????????&#39;</span>  <span class="c1"># &lt;-- Fill in the proper expression</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="alert alert-block alert-info">
**Q:** What is the expression for `w0` in the equation above?
</div>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Step-4.--Repeat-steps-2-&amp;-3-many-times.">Step 4.  Repeat steps 2 &amp; 3 many times.<a class="anchor-link" href="#Step-4.--Repeat-steps-2-&amp;-3-many-times."> </a></h2><p>Now, we'd like to repeat Steps 2 &amp; 3 many times. In doing so, we'll
 perform gradient descent, and move (slowly) down our cost function,
 until we reach a minimum.</p>
<p>We could try to compute these repetitions by hand, for example by repeating
 the cells above. To do so, we'd need to take the new weights we just
 found in Step 3, compute the feedforward solution to our neural network,
 and then update the neural network's weights (which depends on how close
 our neural network's output is to the target value).</p>
<p>But, we want to evaluate this procedure 1000 times. We could do this by
 hand, but it'd be a total pain, and highly error prone. Instead, let's
 ask a computer to do the boring work of multiple repetitions. To do so,
 let's collect the code above, and repeat it 1000 times. We'll wrap our
 code above inside a <code>for-loop</code> to make this efficient,</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">s0</span> <span class="o">=</span> <span class="mi">2</span>                          <span class="c1"># Define the input,</span>
<span class="n">target</span> <span class="o">=</span> <span class="mf">0.7</span>                    <span class="c1"># ... and the target output.</span>

<span class="n">w0</span> <span class="o">=</span> <span class="mi">2</span>                          <span class="c1"># Choose initial values for the weights.</span>
<span class="n">w1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">w2</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>                     <span class="c1"># Set the learning constant.</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>     <span class="c1"># Define the sigmoid anonymous function.</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1000</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>    <span class="c1"># Define a variable to hold the results of each iteration.    </span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>           <span class="c1"># For 1000 iteractions,</span>
    
    <span class="c1">#Step 2. Calculate feedforward solution to get output.</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">w0</span><span class="o">*</span><span class="n">s0</span>                  <span class="c1"># ... activity of first neuron,</span>
    <span class="n">s1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>            <span class="c1"># ... output of first neuron,</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">w1</span><span class="o">*</span><span class="n">s1</span>                  <span class="c1"># ... activity of second neuron,</span>
    <span class="n">s2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>            <span class="c1"># ... output of second neuron,</span>
    <span class="n">out</span><span class="o">=</span> <span class="n">w2</span><span class="o">*</span><span class="n">s2</span>                  <span class="c1"># Output of neural network.</span>
    
    <span class="c1">#Step 3. Update the weights.</span>
    <span class="n">w2</span> <span class="o">=</span> <span class="n">w2</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">out</span><span class="o">-</span><span class="n">target</span><span class="p">)</span><span class="o">*</span><span class="n">s2</span>
    <span class="n">w1</span> <span class="o">=</span> <span class="n">w1</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">out</span><span class="o">-</span><span class="n">target</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">w2</span><span class="o">*</span><span class="n">s2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">s2</span><span class="p">)</span><span class="o">*</span><span class="n">s1</span><span class="p">)</span>
    <span class="n">w0</span> <span class="o">=</span> <span class="n">w0</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">out</span><span class="o">-</span><span class="n">target</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">w2</span><span class="o">*</span><span class="n">s2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">s2</span><span class="p">)</span><span class="o">*</span><span class="n">w1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">s1</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">s1</span><span class="p">)</span><span class="o">*</span><span class="n">s0</span><span class="p">)</span>
    
    <span class="c1"># Save the results of this step! --------------------------------------</span>
    <span class="n">results</span><span class="p">[</span><span class="n">k</span><span class="p">,:]</span> <span class="o">=</span> <span class="p">[</span><span class="n">w2</span><span class="p">,</span><span class="n">w1</span><span class="p">,</span><span class="n">w0</span><span class="p">,</span>  <span class="n">out</span><span class="p">]</span>
    <span class="c1"># Here we save the 3 weights, the neural network output.</span>

<span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;w2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;w1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;w0&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[:,</span><span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;out&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span> <span class="mi">1000</span><span class="o">*</span><span class="p">[</span><span class="n">target</span><span class="p">],</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>  <span class="c1">#... and plot the *target*.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span> <span class="c1">#Iclude a legend,</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration number&#39;</span><span class="p">);</span>         <span class="c1">#... and axis label.</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/A01/backprop_30_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    